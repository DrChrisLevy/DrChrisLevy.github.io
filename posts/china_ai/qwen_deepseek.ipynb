{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7908ac58af685d94",
   "metadata": {
    "collapsed": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Qwen and DeepSeek Releases 2025-01\n",
    "author: Chris Levy\n",
    "draft: false\n",
    "date: '2025-01-28'\n",
    "date-modified: '2025-01-28'\n",
    "image: imgs/say_agentic_one_more_time.jpeg\n",
    "toc: true\n",
    "format:\n",
    "  html:\n",
    "    code-fold: show\n",
    "    page-layout: full\n",
    "    grid:\n",
    "      body-width: 1200px\n",
    "include-in-header:\n",
    "  - text: |\n",
    "      <style>\n",
    "      .cell-output-stdout code {\n",
    "        word-break: break-word !important;\n",
    "        white-space: pre-wrap !important;\n",
    "      }\n",
    "      </style>\n",
    "bibliography: ../../bibliography.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5657e7b6",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "The Chinese labs, DeepSeek and Alibabaâ€™s Qwen, are releasing a lot of models.\n",
    "I wanted to quickly write down some notes so I can keep it all straight in my head.\n",
    "\n",
    "# DeepSeek\n",
    "\n",
    "## DeepSeek-R1\n",
    "\n",
    "- [Github - DeepSeek-R1](https://github.com/deepseek-ai/DeepSeek-R1)\n",
    "- [Paper](https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf)\n",
    "- I use the [DeepSeek Chat Platform](https://platform.deepseek.com/) to use it. The API [platform](https://platform.deepseek.com/) is really good too!\n",
    "- Trained via large-scale reinforcement learning (RL)\n",
    "- Uses DeepSeek-V3-Base as the base model and then employs [GRPO](https://arxiv.org/abs/2402.03300) as the RL framework.\n",
    "    - What emerges first is DeepSeek-R1-Zero\n",
    "    - generates lot chain of thought\n",
    "    - first open source research to show LLMs can develop reasoning capabilities purely through RL, without the need for SFT\n",
    "    - But has issues for practical use cases (poor readability, language mixing)\n",
    "- Pipeline to develop DeepSeek-R1 using RL and SFT\n",
    "    - collect small amount of COT data for cold-start\n",
    "    - fine-tune DeepSeek-V3-Base on cold-start data\n",
    "    - apply RL just as in DeepSeek-R1-Zero\n",
    "    - apply SFT on top of RL\n",
    "    - This is the model we should use for practical use cases\n",
    "- Distilled Models\n",
    "    - DeepSeek-R1 is the teacher model to generate 800K training samples\n",
    "    - fine-tune several smaller dense models using Qwen and Llama\n",
    "\n",
    "\n",
    "<blockquote class=\"twitter-tweet\">\n",
    "<iframe src=\"https://platform.twitter.com/embed/Tweet.html?id=1883957838952947954\" \n",
    "        width=\"550\" \n",
    "        height=\"450\" \n",
    "        frameborder=\"0\" \n",
    "        allowfullscreen>\n",
    "</iframe>\n",
    "</blockquote>\n",
    "\n",
    "\n",
    "\n",
    "![](imgs/deep_seek.png)\n",
    "\n",
    "![](imgs/deepseek_distilled.png)\n",
    "\n",
    "\n",
    "- The smaller distilled versions can be run locally through [ollama](https://ollama.com/library/deepseek-r1) for example ---> `ollama run deepseek-r1`.\n",
    "- [the-illustrated-deepseek-r1 blog post](https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47364e51",
   "metadata": {},
   "source": [
    "## Janus-Pro\n",
    "\n",
    "- [Github - Janus](https://github.com/deepseek-ai/Janus)\n",
    "- [Paper](https://github.com/deepseek-ai/Janus/blob/main/janus_pro_tech_report.pdf)\n",
    "- [Huggingface - Janus-Pro-webgpu - 1B](https://huggingface.co/spaces/webml-community/janus-pro-webgpu)\n",
    "- [7B Model](https://huggingface.co/deepseek-ai/Janus-Pro-7B)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12700f3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
