{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f728359e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Deploying a Remote MCP Server to Modal\n",
    "author: Chris Levy\n",
    "draft: false\n",
    "date: '2025-08-08'\n",
    "date-modified: '2025-08-08'\n",
    "image: mcp2_img.png\n",
    "toc: true\n",
    "description: Deploying a remote MCP server to Modal, and connecting it to hosts such as Claude Desktop and Cursor.\n",
    "tags:\n",
    "  - MCP\n",
    "  - LLMS\n",
    "  - fastmcp\n",
    "  - tools\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87da846",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This video walks through all the content of this post.\n",
    "\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/MCFES06LMUs\" title=\"YouTube video\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n",
    "\n",
    "\n",
    "In a [previous post](https://drchrislevy.github.io/blog), I took some notes on MCP as I went through the documentation at a high level.\n",
    "\n",
    "In this post I will deploy a remote MCP server to Modal, and connect it to Claude Desktop.\n",
    "Claude Desktop, as a host with clients, does not support all the functionality of MCP at the moment.\n",
    "However, it's easy to set up.\n",
    "\n",
    "If you are not familiar with MCP, I highly suggest reading the [MCP documentation](https://modelcontextprotocol.io/docs/getting-started/intro).\n",
    "\n",
    "To follow along you will need to\n",
    "- have a Modal account and have the Modal CLI installed\n",
    "- have a Claude Desktop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b501daec",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Let's build some tools for our MCP Server.\n",
    "\n",
    "### Python Code Execution in a Modal Sandbox\n",
    "\n",
    "We will build a tool that executes arbitrary python code in a sandboxed environment using Modal Sandboxes.\n",
    "Some relevant docs from Modal on this topic if you are interested:\n",
    "\n",
    "- [Build a stateful, sandboxed code interpreter](https://modal.com/docs/examples/simple_code_interpreter#build-a-stateful-sandboxed-code-interpreter)\n",
    "- [Run arbitrary code in a sandboxed environment](https://modal.com/docs/examples/safe_code_execution#run-arbitrary-code-in-a-sandboxed-environment)\n",
    "- [Build a coding agent with Modal Sandboxes and LangGraph](https://modal.com/docs/examples/agent#build-a-coding-agent-with-modal-sandboxes-and-langgraph)\n",
    "\n",
    "\n",
    "- create a python file called `python_sandbox.py` with the following contents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec3a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Note: this could change in the future as modal improves.\n",
    "    But at the time of writing this, the stdout channel does not work well\n",
    "    with from_id at the moment. That is why we make use of the file system.\n",
    "\n",
    "    This module implements a file-based code execution driver in a Modal sandbox.\n",
    "    This module was specifically designed to support detached execution. This means\n",
    "    that you can pass around the Sandbox's object ID and control the same process\n",
    "    from a different process later.\n",
    "    It reads commands from '/modal/io/stdin.txt'; each JSON command must include\n",
    "    a \"code\" field and a user-supplied \"command_id\". The execution output (stdout and stderr)\n",
    "    is written to '/modal/io/<command_id>.txt'.\n",
    "\n",
    "    Based off this GIST from Peyton (Modal Developer)\n",
    "    https://gist.github.com/pawalt/7cd4dc56de29e9cddba4d97decaab1ad\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import Any, Dict, Optional\n",
    "from uuid import uuid4\n",
    "\n",
    "import modal\n",
    "\n",
    "DRIVER_PROGRAM = \"\"\"\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from contextlib import redirect_stderr, redirect_stdout\n",
    "from io import StringIO\n",
    "from typing import Any, Generator\n",
    "\n",
    "IO_DATA_DIR = '/modal/io'\n",
    "os.makedirs(IO_DATA_DIR, exist_ok=True)\n",
    "STDIN_FILE = os.path.join(IO_DATA_DIR, 'stdin.txt')\n",
    "\n",
    "with open(STDIN_FILE, 'w') as f:\n",
    "    f.write('')\n",
    "\n",
    "\n",
    "def tail_f(filename: str) -> Generator[str, None, None]:\n",
    "    # Continuously yields new lines from the file.\n",
    "    with open(filename, 'r') as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                time.sleep(0.1)\n",
    "                continue\n",
    "            yield line\n",
    "\n",
    "\n",
    "globals: dict[str, Any] = {}\n",
    "for line in tail_f(STDIN_FILE):\n",
    "    line = line.strip()\n",
    "    print(f'Received line: {line} len: {len(line)}')\n",
    "    if not line:\n",
    "        continue\n",
    "\n",
    "    command = json.loads(line)\n",
    "    if (code := command.get('code')) is None:\n",
    "        print(json.dumps({'error': 'No code to execute'}))\n",
    "        continue\n",
    "\n",
    "    if (command_id := command.get('command_id')) is None:\n",
    "        print(json.dumps({'error': 'No command_id'}))\n",
    "        continue\n",
    "\n",
    "    stdout_io, stderr_io = StringIO(), StringIO()\n",
    "    with redirect_stdout(stdout_io), redirect_stderr(stderr_io):\n",
    "        try:\n",
    "            exec(code, globals)\n",
    "        except Exception as e:\n",
    "            print(f'{type(e).__name__}: {e}', file=sys.stderr)\n",
    "\n",
    "    with open(os.path.join(IO_DATA_DIR, f'{command_id}.txt'), 'w') as f:\n",
    "        f.write(\n",
    "            json.dumps(\n",
    "                {\n",
    "                    'stdout': stdout_io.getvalue(),\n",
    "                    'stderr': stderr_io.getvalue(),\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ModalSandbox:\n",
    "    IMAGE = modal.Image.debian_slim().pip_install(\"pandas\", \"tabulate\")\n",
    "    IO_DATA_DIR = \"/modal/io\"\n",
    "    STDIN_FILE = os.path.join(IO_DATA_DIR, \"stdin.txt\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sandbox_id: Optional[str] = None,\n",
    "        timeout: int = 60 * 60,\n",
    "        init_script: Optional[str] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        # check if running Sandbox already exists\n",
    "        if sandbox_id is not None:\n",
    "            existing_sb = self._get_running_sandbox_from_id(sandbox_id)\n",
    "            if existing_sb is not None:\n",
    "                self.sandbox = existing_sb\n",
    "                return\n",
    "\n",
    "        app = modal.App.lookup(\"python-sandbox\", create_if_missing=True)\n",
    "        self.sandbox = modal.Sandbox.create(\n",
    "            \"python\",\n",
    "            \"-c\",\n",
    "            DRIVER_PROGRAM,\n",
    "            image=self.IMAGE,\n",
    "            app=app,\n",
    "            timeout=timeout,\n",
    "            **kwargs,\n",
    "        )\n",
    "        if init_script:\n",
    "            self.run_code(init_script)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_running_sandbox_from_id(cls, sb_id: str) -> Optional[modal.Sandbox]:\n",
    "        # Returns None if the sandbox is not running or if the sb_id is not found\n",
    "        # or some error occurs\n",
    "        try:\n",
    "            sb = modal.Sandbox.from_id(sb_id)\n",
    "        except Exception:\n",
    "            return None\n",
    "        # check if the sandbox is running\n",
    "        if sb.poll() is None:\n",
    "            return sb\n",
    "\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def sandbox_id(self) -> str:\n",
    "        return self.sandbox.object_id\n",
    "\n",
    "    def terminate(self) -> None:\n",
    "        self.sandbox.terminate()\n",
    "\n",
    "    def run_code(self, code: str) -> Dict[str, str]:\n",
    "        command_id = uuid4().hex\n",
    "\n",
    "        # 1. Write code into a STDIN file on the sandbox.\n",
    "        with self.sandbox.open(self.STDIN_FILE, \"a\") as f:\n",
    "            f.write(json.dumps({\"code\": code, \"command_id\": command_id}))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        # 2. The sandbox polls this STDIN file for changes,\n",
    "        # executes the added code, then saves the output to a file.\n",
    "        out_file = os.path.join(self.IO_DATA_DIR, f\"{command_id}.txt\")\n",
    "\n",
    "        # 3. We poll the Sandbox to check if it has created the output file,\n",
    "        # and if so, return the output from the file.\n",
    "        while True:\n",
    "            try:\n",
    "                with self.sandbox.open(out_file, \"r\") as f:\n",
    "                    result = json.load(f)\n",
    "                    return result\n",
    "            except FileNotFoundError:\n",
    "                time.sleep(0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e43cdb",
   "metadata": {},
   "source": [
    "This is truly awesome because it allows you to execute arbitrary python code in a sandboxed environment without worrying about the security implications of running code in your local environment. Here is a demo of how to use it locally for testing. This code snippet below within `run_code` is not running locally, its running in a Modal Sandbox in the cloud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2cda954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stdout': '   a\\n0  1\\n1  2\\n2  3\\n', 'stderr': ''}\n",
      "   a\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sb = ModalSandbox()\n",
    "\n",
    "res = sb.run_code(\"\"\"\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3]})\n",
    "print(df)\n",
    "\"\"\")\n",
    "print(res)\n",
    "print(res['stdout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c690f4f",
   "metadata": {},
   "source": [
    "### Image Generation with Qwen Image\n",
    "\n",
    "\n",
    "Create a python file called `image_gen_qwen.py` and add the following code below.\n",
    "Deploy it with `modal deploy image_gen_qwen.py`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22957a3",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "\n",
    "import modal\n",
    "\n",
    "# Modal Volume URL configuration\n",
    "MODAL_WORKSPACE = \"drchrislevy\"  # replace with your modal workspace\n",
    "MODAL_ENVIRONMENT = \"main\"  # replace with your modal environment\n",
    "VOLUME_NAME = \"qwen_generated_images\"  # replace with your modal volume name\n",
    "\n",
    "# Image with required dependencies\n",
    "image = (\n",
    "    modal.Image.debian_slim()\n",
    "    .apt_install([\"git\"])\n",
    "    .pip_install(\n",
    "        [\n",
    "            \"torch\",\n",
    "            \"torchvision\",\n",
    "            \"git+https://github.com/huggingface/diffusers\",\n",
    "            \"transformers\",\n",
    "            \"accelerate\",\n",
    "            \"pillow\",\n",
    "            \"sentencepiece\",\n",
    "            \"python-dotenv\",\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "app = modal.App(\"qwen-image-generator\", image=image)\n",
    "\n",
    "hf_hub_cache = modal.Volume.from_name(\"hf_hub_cache\", create_if_missing=True)\n",
    "images_volume = modal.Volume.from_name(VOLUME_NAME, create_if_missing=True)\n",
    "\n",
    "\n",
    "@app.cls(\n",
    "    image=image,\n",
    "    gpu=\"H100\",\n",
    "    secrets=[\n",
    "        modal.Secret.from_name(\"huggingface-secret\"),\n",
    "    ],\n",
    "    timeout=60 * 10,\n",
    "    volumes={\n",
    "        \"/root/.cache/huggingface/hub/\": hf_hub_cache,\n",
    "        \"/root/generated_images\": images_volume,\n",
    "    },\n",
    "    scaledown_window=60 * 60,\n",
    "    max_containers=2,\n",
    ")\n",
    "@modal.concurrent(max_inputs=1)\n",
    "class QwenImageGenerator:\n",
    "    @modal.enter()\n",
    "    def setup(self):\n",
    "        \"\"\"Load Qwen-Image model once per container\"\"\"\n",
    "        import torch\n",
    "        from diffusers import DiffusionPipeline\n",
    "\n",
    "        print(\"Loading Qwen/Qwen-Image model...\")\n",
    "\n",
    "        # Set device and dtype (CUDA is available)\n",
    "        self.torch_dtype = torch.bfloat16\n",
    "        self.device = \"cuda\"\n",
    "\n",
    "        # Load the pipeline\n",
    "        self.pipe = DiffusionPipeline.from_pretrained(\n",
    "            \"Qwen/Qwen-Image\",\n",
    "            torch_dtype=self.torch_dtype,\n",
    "            cache_dir=\"/root/.cache/huggingface/hub\",\n",
    "        )\n",
    "        self.pipe = self.pipe.to(self.device)\n",
    "\n",
    "        print(\"Model loaded successfully!\")\n",
    "\n",
    "        # Set up volume path for storing images\n",
    "        self.images_path = \"/root/generated_images\"\n",
    "\n",
    "        # Define aspect ratios\n",
    "        self.aspect_ratios = {\n",
    "            \"1:1\": (1328, 1328),\n",
    "            \"16:9\": (1664, 928),\n",
    "            \"9:16\": (928, 1664),\n",
    "            \"4:3\": (1472, 1140),\n",
    "            \"3:4\": (1140, 1472),\n",
    "        }\n",
    "\n",
    "    def generate_image(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        negative_prompt: str = \"\",\n",
    "        aspect_ratio: str = \"16:9\",\n",
    "        true_cfg_scale: float = 3.5,\n",
    "        seed: int = 42,\n",
    "        randomize_seed=False,\n",
    "        num_inference_steps: int = 50,\n",
    "    ):\n",
    "        \"\"\"Generate image from text prompt and save to Modal Volume\"\"\"\n",
    "        import random\n",
    "        import uuid\n",
    "        from datetime import datetime\n",
    "\n",
    "        import numpy as np\n",
    "        import torch\n",
    "\n",
    "        MAX_SEED = np.iinfo(np.int32).max\n",
    "        if randomize_seed:\n",
    "            seed = random.randint(0, MAX_SEED)\n",
    "        generator = torch.Generator(device=self.device).manual_seed(seed)\n",
    "        print(f\"Generating image for prompt: {prompt}\")\n",
    "\n",
    "        # Get dimensions from aspect ratio\n",
    "        if aspect_ratio in self.aspect_ratios:\n",
    "            width, height = self.aspect_ratios[aspect_ratio]\n",
    "        else:\n",
    "            width, height = self.aspect_ratios[\"16:9\"]  # default\n",
    "\n",
    "        # Generate image\n",
    "        image = self.pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            width=width,\n",
    "            height=height,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            true_cfg_scale=true_cfg_scale,\n",
    "            generator=generator,\n",
    "        ).images[0]\n",
    "\n",
    "        # Create unique filename\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        unique_id = str(uuid.uuid4())[:8]\n",
    "        filename = f\"qwen_generated_{timestamp}_{unique_id}.png\"\n",
    "        file_path = os.path.join(self.images_path, filename)\n",
    "\n",
    "        # Save image to Modal Volume\n",
    "        try:\n",
    "            image.save(file_path, format=\"PNG\")\n",
    "            print(f\"Image saved successfully to volume: {file_path}\")\n",
    "\n",
    "            # Generate Modal Volume URL\n",
    "            # Format: https://modal.com/api/volumes/{workspace}/{env}/{volume_name}/files/content?path={filename}\n",
    "            image_url = f\"https://modal.com/api/volumes/{MODAL_WORKSPACE}/{MODAL_ENVIRONMENT}/{VOLUME_NAME}/files/content?path={filename}\"\n",
    "\n",
    "            return {\n",
    "                \"image_url\": image_url,\n",
    "                \"filename\": filename,\n",
    "                \"file_path\": file_path,\n",
    "                \"prompt\": prompt,\n",
    "                \"negative_prompt\": negative_prompt,\n",
    "                \"aspect_ratio\": aspect_ratio,\n",
    "                \"dimensions\": {\"width\": width, \"height\": height},\n",
    "                \"volume_path\": f\"/root/generated_images/{filename}\",\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving to volume: {e}\")\n",
    "            raise\n",
    "\n",
    "    @modal.fastapi_endpoint(\n",
    "        method=\"POST\",\n",
    "        docs=True,\n",
    "    )\n",
    "    def generate_image_endpoint(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        negative_prompt: str = \"\",\n",
    "        aspect_ratio: str = \"16:9\",\n",
    "        true_cfg_scale: float = 4.0,\n",
    "        seed: int = 42,\n",
    "        randomize_seed: bool = False,\n",
    "        num_inference_steps: int = 50,\n",
    "    ):\n",
    "        \"\"\"Public FastAPI endpoint for image generation\"\"\"\n",
    "        return self.generate_image(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            aspect_ratio=aspect_ratio,\n",
    "            true_cfg_scale=true_cfg_scale,\n",
    "            seed=seed,\n",
    "            randomize_seed=randomize_seed,\n",
    "            num_inference_steps=num_inference_steps,\n",
    "        )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71ff6d0",
   "metadata": {},
   "source": [
    "Once you deploy the endpoint you will get a URL:\n",
    "For this demo the url is \n",
    "\n",
    "```\n",
    "https://drchrislevy--qwen-image-generator-qwenimagegenerator-gen-5fbcf5.modal.run/\n",
    "```\n",
    "\n",
    "You can always test it with the docs at `https://drchrislevy--qwen-image-generator-qwenimagegenerator-gen-5fbcf5.modal.run/docs/`\n",
    "\n",
    "We can test it quickly with the requests library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ac37c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_url': 'https://modal.com/api/volumes/drchrislevy/main/qwen_generated_images/files/content?path=qwen_generated_20250808_112635_d7cb3e87.png',\n",
       " 'filename': 'qwen_generated_20250808_112635_d7cb3e87.png',\n",
       " 'file_path': '/root/generated_images/qwen_generated_20250808_112635_d7cb3e87.png',\n",
       " 'prompt': 'A beautiful view looking down a road with cute houses on either side and mountains in the background.',\n",
       " 'negative_prompt': 'blurry, low quality, distorted',\n",
       " 'aspect_ratio': '16:9',\n",
       " 'dimensions': {'width': 1664, 'height': 928},\n",
       " 'volume_path': '/root/generated_images/qwen_generated_20250808_112635_d7cb3e87.png'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "endpoint_url = \"https://drchrislevy--qwen-image-generator-qwenimagegenerator-gen-5fbcf5.modal.run/\"\n",
    "\n",
    "response = requests.post(\n",
    "    endpoint_url,\n",
    "    params={\n",
    "        \"prompt\": 'A beautiful view looking down a road with cute houses on either side and mountains in the background.',\n",
    "        \"negative_prompt\": \"blurry, low quality, distorted\",\n",
    "        \"aspect_ratio\": \"16:9\",\n",
    "        \"true_cfg_scale\": 4.0,\n",
    "        \"randomize_seed\": True,\n",
    "        \"num_inference_steps\": 50,\n",
    "    },\n",
    "    timeout=120,\n",
    ")\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c439db0",
   "metadata": {},
   "source": [
    "<img src=\"static_blog_imgs/road_mountains.png\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c42018",
   "metadata": {},
   "source": [
    "## Deploying the MCP Server with FastMCP and Modal\n",
    "\n",
    "Now create a final file called `mcp_demo.py` with the following contents.\n",
    "We add some other fake tools/resources/sampling to show that \n",
    "the FastMCP library supports those features, even though the Claude Desktop do not fully yet.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384e4108",
   "metadata": {},
   "source": [
    "```python\n",
    "# server.py\n",
    "import modal\n",
    "\n",
    "image = (\n",
    "    modal.Image.debian_slim()\n",
    "    .pip_install(\"fastapi[standard]\", \"fastmcp>=2.3.2\")\n",
    "    .add_local_file(\"posts/mcp/python_sandbox.py\", remote_path=\"/root/python_sandbox.py\")\n",
    ")\n",
    "\n",
    "app = modal.App(\"fastmcp-modal-demo\", image=image)\n",
    "\n",
    "\n",
    "@app.function(scaledown_window=60 * 60)\n",
    "@modal.concurrent(max_inputs=100)\n",
    "@modal.asgi_app()\n",
    "def mcp_asgi():\n",
    "    # Everything below runs inside the Modal container\n",
    "    from fastmcp import Context, FastMCP\n",
    "    from python_sandbox import ModalSandbox\n",
    "    from starlette.responses import JSONResponse\n",
    "\n",
    "    sb = ModalSandbox()\n",
    "\n",
    "    mcp = FastMCP(\n",
    "        name=\"HelpfulAssistant\",\n",
    "        instructions=\"\"\"This server provides some useful tools for the user.\"\"\",\n",
    "    )\n",
    "\n",
    "    @mcp.tool\n",
    "    def execute_python_code(code: str) -> dict:\n",
    "        \"\"\"Run arbitrary python code in a sandboxed environment. It is stateful and persistent between calls.\n",
    "        Install packages with: os.system(\"pip install <package_name>\")\n",
    "        \"\"\"\n",
    "        return sb.run_code(code)\n",
    "\n",
    "    @mcp.tool\n",
    "    def text2image(\n",
    "        prompt: str,\n",
    "        negative_prompt: str = \"blurry, low quality, distorted\",\n",
    "        aspect_ratio: str = \"16:9\",\n",
    "        true_cfg_scale: float = 4.0,\n",
    "        randomize_seed: bool = True,\n",
    "        num_inference_steps: int = 50,\n",
    "        seed: int = 42,\n",
    "    ) -> dict:\n",
    "        \"\"\"Given the text prompt and other parameters,\n",
    "        uses an AI text2image model to generate an image and return the image url.\n",
    "        Always return at least the image url so the user can see the image.\"\"\"\n",
    "        import requests\n",
    "\n",
    "        endpoint_url = \"https://drchrislevy--qwen-image-generator-qwenimagegenerator-gen-5fbcf5.modal.run/\"\n",
    "        response = requests.post(\n",
    "            endpoint_url,\n",
    "            params={\n",
    "                \"prompt\": prompt,\n",
    "                \"negative_prompt\": negative_prompt,\n",
    "                \"aspect_ratio\": aspect_ratio,\n",
    "                \"true_cfg_scale\": true_cfg_scale,\n",
    "                \"randomize_seed\": randomize_seed,\n",
    "                \"num_inference_steps\": num_inference_steps,\n",
    "                \"seed\": seed,\n",
    "            },\n",
    "            timeout=120,\n",
    "        )\n",
    "        return response.json()\n",
    "\n",
    "    @mcp.resource(\"users://{user_id}/profile\")\n",
    "    def get_user_profile(user_id: int) -> dict:\n",
    "        \"\"\"Retrieves a user's profile by ID.\"\"\"\n",
    "        # The {user_id} in the URI is extracted and passed to this function\n",
    "        return {\"id\": user_id, \"name\": f\"User {user_id}\", \"status\": \"active\"}\n",
    "\n",
    "    @mcp.resource(\"data://config\")\n",
    "    def get_config() -> dict:\n",
    "        \"\"\"Provides application configuration as JSON.\"\"\"\n",
    "        return {\n",
    "            \"theme\": \"dark\",\n",
    "            \"version\": \"1.2.0\",\n",
    "            \"features\": [\"tools\", \"resources\"],\n",
    "        }\n",
    "\n",
    "    # Optional plain HTTP health check (easy to curl)\n",
    "    @mcp.custom_route(\"/health\", methods=[\"GET\"])\n",
    "    async def health(_req):\n",
    "        return JSONResponse({\"status\": \"ok\"})\n",
    "\n",
    "    @mcp.prompt\n",
    "    def ask_about_topic(topic: str) -> str:\n",
    "        \"\"\"Generates a user message asking for an explanation of a topic.\"\"\"\n",
    "        return f\"Can you please explain the concept of '{topic}'?\"\n",
    "\n",
    "    @mcp.tool\n",
    "    async def analyze_sentiment(text: str, ctx: Context) -> dict:\n",
    "        \"\"\"Analyze the sentiment of text using the client's LLM.\"\"\"\n",
    "        prompt = f\"\"\"Analyze the sentiment of the following text as positive, negative, or neutral. \n",
    "        Just output a single word - 'positive', 'negative', or 'neutral'.\n",
    "        \n",
    "        Text to analyze: {text}\"\"\"\n",
    "\n",
    "        # Request LLM analysis\n",
    "        response = await ctx.sample(prompt)\n",
    "\n",
    "        # Process the LLM's response\n",
    "        sentiment = response.text.strip().lower()\n",
    "\n",
    "        # Map to standard sentiment values\n",
    "        if \"positive\" in sentiment:\n",
    "            sentiment = \"positive\"\n",
    "        elif \"negative\" in sentiment:\n",
    "            sentiment = \"negative\"\n",
    "        else:\n",
    "            sentiment = \"neutral\"\n",
    "\n",
    "        return {\"text\": text, \"sentiment\": sentiment}\n",
    "\n",
    "    # Expose the MCP server as an ASGI app.\n",
    "    # Default transport is Streamable HTTP; we mount at /mcp\n",
    "    return mcp.http_app(path=\"/mcp\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c475981d",
   "metadata": {},
   "source": [
    "Deploy the MCP server with `modal deploy mcp_demo.py`.\n",
    "\n",
    "The modal endpoint url will look something like `https://drchrislevy--fastmcp-modal-demo-mcp-asgi.modal.run`\n",
    "but the MCP server is available at `https://drchrislevy--fastmcp-modal-demo-mcp-asgi.modal.run/mcp`. This latter\n",
    "link is the path for the remote MCP server.\n",
    "\n",
    "<img src=\"static_blog_imgs/claudemcp1.png\" width=\"50%\">\n",
    "<img src=\"static_blog_imgs/claudemcp2.png\" width=\"50%\">\n",
    "<img src=\"static_blog_imgs/claudemcp3.png\" width=\"50%\">\n",
    "<img src=\"static_blog_imgs/claudemcp4.png\" width=\"50%\">\n",
    "<img src=\"static_blog_imgs/claudemcp5.png\" width=\"50%\">\n",
    "\n",
    "\n",
    "You can then add the endpoint url to your Claude Desktop and try out the MCP server there.\n",
    "Similarly, you could also configure it in your Cursor IDE, etc. In Cursor your `mcp.json` \n",
    "could look something like\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"mcpServers\": {\n",
    "    \"helpful-assistant\": {\n",
    "      \"transport\": \"streamable-http\",\n",
    "      \"url\": \"https://drchrislevy--fastmcp-modal-demo-mcp-asgi.modal.run/mcp/\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c23084",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e4d0692",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
