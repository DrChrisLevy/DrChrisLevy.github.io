{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f1a41a29",
   "metadata": {},
   "source": [
    "---\n",
    "title: Function Calling with Hermes-2-Pro-Mistral-7B\n",
    "author: Chris Levy\n",
    "date: '2024-03-16'\n",
    "date-modified: '2024-03-18'\n",
    "image: imgs/hermes.jpeg\n",
    "toc: true\n",
    "format:\n",
    "  html:\n",
    "    code-fold: show\n",
    "    page-layout: full\n",
    "include-in-header:\n",
    "  - text: |\n",
    "      <style>\n",
    "      .cell-output-stdout code {\n",
    "        word-break: break-wor !important;\n",
    "        white-space: pre-wrap !important;\n",
    "      }\n",
    "      </style>\n",
    "bibliography: ../../bibliography.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d9b4f",
   "metadata": {},
   "source": [
    "![](imgs/hermes.jpeg){width=75%}\n",
    "\n",
    "# Introduction\n",
    "\n",
    "\n",
    "\n",
    "In this post we take a look at the function calling capabilities of the open source model\n",
    "`NousResearch/Hermes-2-Pro-Mistral-7B`  (@Hermes-2-Pro-Mistral-7B)\n",
    " \n",
    "- [Twitter announcement](https://x.com/Teknium1/status/1768023030843015208?s=20)\n",
    "- [GitHub Repo for Function Calling](https://github.com/NousResearch/Hermes-Function-Calling)\n",
    "- [Hugging Face Model Card](https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B)\n",
    "\n",
    "# ENV Setup\n",
    "\n",
    "Start by creating a virtual environment: \n",
    "\n",
    "```\n",
    "python3 -m venv env\n",
    "source env/bin/activate\n",
    "```\n",
    "\n",
    "Then install:\n",
    "\n",
    "```\n",
    "pip install openai\n",
    "pip install python-dotenv # or define your environment variables differently\n",
    "pip install langchain # utilities for converting functions to OpenAI tools format.\n",
    "```\n",
    "\n",
    "I also have:\n",
    "\n",
    "- an [OpenAI account](https://platform.openai.com/api-keys) with an API key.\n",
    "- Hugging Face Account, Access Token, and created [inference endpoint](https://huggingface.co/inference-endpoints/dedicated) with the model `NousResearch/Hermes-2-Pro-Mistral-7B`.\n",
    "- a [together.ai account](https://api.together.xyz/settings/api-keys) with an API key.\n",
    "\n",
    "In my `.env` file I have the following:\n",
    "```\n",
    "OPENAI_API_KEY=your_key\n",
    "HUGGING_FACE_ACCESS_TOKEN=your_key\n",
    "HUGGING_FACE_ENDPOINT_URL=url_for_endpoint\n",
    "TOGETHER_AI_BASE_URL=https://api.together.xyz/v1\n",
    "TOGETHER_API_KEY=your_key\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6aa857a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:01:47.350311Z",
     "start_time": "2024-03-18T12:01:47.339076Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# | output: false\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "HUGGING_FACE_ACCESS_TOKEN = os.environ[\"HUGGING_FACE_ACCESS_TOKEN\"]\n",
    "HUGGING_FACE_ENDPOINT_URL = os.environ[\"HUGGING_FACE_ENDPOINT_URL\"]\n",
    "TOGETHER_API_KEY = os.environ[\"TOGETHER_API_KEY\"]\n",
    "TOGETHER_AI_BASE_URL = os.environ[\"TOGETHER_AI_BASE_URL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1f83b",
   "metadata": {},
   "source": [
    "# LLM Inference Class\n",
    "\n",
    "In a previous [blog post](https://drchrislevy.github.io/posts/llm_inference_class/llm_inference.html) I discussed how we can use the OpenAI python client to run inference with open source models through services that are OpenAI compatible. I'm going to copy part of the code here. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "247a1ebc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:01:50.415476Z",
     "start_time": "2024-03-18T12:01:50.407347Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Any, Dict, Optional, Union\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from openai import OpenAI\n",
    "from openai._streaming import Stream\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "from openai.types.chat.chat_completion_chunk import ChatCompletionChunk\n",
    "\n",
    "today = datetime.now().strftime(\"%A %Y-%m-%d\")\n",
    "\n",
    "\n",
    "class OpenAIChatCompletion:\n",
    "    clients: Dict = dict()\n",
    "\n",
    "    @classmethod\n",
    "    def _load_client(cls, base_url: Optional[str] = None, api_key: Optional[str] = None) -> OpenAI:\n",
    "        client_key = (base_url, api_key)\n",
    "        if OpenAIChatCompletion.clients.get(client_key) is None:\n",
    "            OpenAIChatCompletion.clients[client_key] = OpenAI(base_url=base_url, api_key=api_key)\n",
    "        return OpenAIChatCompletion.clients[client_key]\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        model: str,\n",
    "        messages: list,\n",
    "        base_url: Optional[str] = None,\n",
    "        api_key: Optional[str] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Union[ChatCompletion, Stream[ChatCompletionChunk]]:\n",
    "        # https://platform.openai.com/docs/api-reference/chat/create\n",
    "        # https://github.com/openai/openai-python\n",
    "        client = self._load_client(base_url, api_key)\n",
    "        return client.chat.completions.create(model=model, messages=messages, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759379c6",
   "metadata": {},
   "source": [
    "Simply use it like this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e8fa468d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:01:53.131468Z",
     "start_time": "2024-03-18T12:01:52.062523Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-945ya3wcBWQeIbmzffGotEPMNnU66', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1710763312, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=9, prompt_tokens=9, total_tokens=18))\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAIChatCompletion()\n",
    "print(llm(model=\"gpt-3.5-turbo-0125\", messages=[dict(role=\"user\", content=\"Hello!\")]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1748e8c9",
   "metadata": {},
   "source": [
    "We can also use the same class to run inference with `Hermes-2-Pro-Mistral-7B` through a Hugging Face Inference endpoint.\n",
    "You don't need to use an inference endpoint to run this model. You could use the transformers library directly\n",
    "and run it locally. Remember to use the proper [prompt format](https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B#prompt-format). I'm using the messages format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "111e9c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:02:07.938856Z",
     "start_time": "2024-03-18T12:01:53.821982Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open source AI is important for several reasons:\n",
      "\n",
      "1. Transparency: Open source AI allows developers and researchers to review the code, understand how it works, and verify its correctness. This transparency ensures trust in the system and can lead to more reliable and secure AI applications.\n",
      "\n",
      "2. Collaboration: Open source encourages collaboration among developers, researchers, and users from around the world. By sharing knowledge and efforts, the community can collectively drive innovation forward, resulting in faster advancements in the field of AI.\n",
      "\n",
      "3. Accessibility: Open source AI makes it possible for anyone to access and use cutting-edge AI technologies, not just those with large budgets or exclusive access. This democratizes AI and ensures that it can benefit everyone, not just those who can afford proprietary solutions.\n",
      "\n",
      "4. Flexibility: With open source AI, users have the freedom to modify and adapt the code to fit their specific needs. This flexibility allows for customized solutions that can better address unique problems and requirements.\n",
      "\n",
      "5. Learning and Education: Open source AI provides a valuable resource for learning and education. Students, researchers, and developers can study the code, understand the underlying principles, and gain practical experience in using and improving AI systems.\n",
      "\n",
      "6. Competition and Market Dynamics: Open source AI fosters a competitive environment by encouraging innovation and rapid development. This can lead to improvements in efficiency, performance, and overall quality of AI solutions. Additionally, it can create a diverse ecosystem with multiple players, reducing the risk of monopolies and promoting a healthy market dynamics.\n",
      "\n",
      "7. Resilience: Open source AI can be more resilient to cyberattacks since the code is openly available for review and audit. Additionally, a diverse community can help identify and address potential vulnerabilities more effectively.\n",
      "\n",
      "In summary, open source AI is important as it promotes transparency, collaboration, accessibility, flexibility, and learning while fostering innovation, competition, and resilience in the field of artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    llm(\n",
    "        model=\"tgi\",\n",
    "        api_key=HUGGING_FACE_ACCESS_TOKEN,\n",
    "        base_url=HUGGING_FACE_ENDPOINT_URL,\n",
    "        messages=[\n",
    "            dict(\n",
    "                role=\"system\",\n",
    "                content=\"You are an OpenSource LLM that rivals OpenAI GPT. Your goal is to bring open source AI to everyone!\",\n",
    "            ),\n",
    "            dict(role=\"user\", content=\"Explain why open source AI is important.\"),\n",
    "        ],\n",
    "        max_tokens=2000,\n",
    "        temperature=1,\n",
    "    )\n",
    "    .choices[0]\n",
    "    .message.content\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc3a5a8",
   "metadata": {},
   "source": [
    "# Function Calling Capabilities\n",
    "\n",
    "First we will define some functions/tools which the LLM will have access to.\n",
    "Here I use `langchain` to convert the Python functions into the `tools` format used\n",
    "by OpenAI. It's much faster than writing those JSON objects by hand.\n",
    "Note that `Hermes-2-Pro-Mistral-7B` also uses this same format!\n",
    "\n",
    "I am leaving out the actual logic for each function. I mainly want to test the models\n",
    "ability to pick out the correct function and arguments. The important step here is to document each function and argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "294415fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:02:07.956730Z",
     "start_time": "2024-03-18T12:02:07.953944Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather_forecast(location: str, date: str) -> str:\n",
    "    \"\"\"\n",
    "    Provides a weather forecast for a given location and date.\n",
    "\n",
    "    Args:\n",
    "        location (str): The name of the city and state, e.g. 'San Francisco, CA'.\n",
    "        date (str): The date of the forecast in YYYY-MM-DD format, e.g. '2023-07-01'.\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing the weather forecast, e.g. 'Partly cloudy with a high of 72F (22C).'\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "@tool\n",
    "def book_flight(\n",
    "    departure_city: str,\n",
    "    arrival_city: str,\n",
    "    departure_date: str,\n",
    "    return_date: str,\n",
    "    num_passengers: int,\n",
    "    cabin_class: str,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Book a round-trip flight for the given parameters.\n",
    "\n",
    "    Args:\n",
    "        departure_city (str): The full city name with the departure airport, e.g. \"Toronto\".\n",
    "        arrival_city (str): The full city name with the arrival airport, e.g. \"Austin\".\n",
    "        departure_date (str): The departure date in YYYY-MM-DD format.\n",
    "        return_date (str): The return date in YYYY-MM-DD format.\n",
    "        num_passengers (int): The number of passengers.\n",
    "        cabin_class (str): The cabin class, e.g. \"economy\", \"business\", \"first\".\n",
    "\n",
    "    Returns:\n",
    "        dict: A dict with the booking details including airline, flight numbers, price and booking confirmation code.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "@tool\n",
    "def book_movie_tickets(movie_name: str, theater_name: str, date: str, time: str, num_tickets: int) -> dict:\n",
    "    \"\"\"\n",
    "    Book movie tickets for the given movie, theater, date, time, and number of tickets.\n",
    "    Args:\n",
    "        movie_name (str): The name of the movie.\n",
    "        theater_name (str): The name of the theater.\n",
    "        date (str): The date of the movie showing (YYYY-MM-DD).\n",
    "        time (str): The time of the movie showing (HH:MM).\n",
    "        num_tickets (int): The number of tickets to book for the movie.\n",
    "    Returns:\n",
    "        dict: Returns a dictionary with booking details if successful, otherwise returns a dictionary with an error message.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "@tool\n",
    "def translate_text(text: str, target_language: str) -> str:\n",
    "    \"\"\"\n",
    "    Translate the given text into the specified target language.\n",
    "    Args:\n",
    "        text (str): The text to be translated.\n",
    "        target_language (str): The target language code (e.g., 'es' for Spanish, 'fr' for French).\n",
    "    Returns:\n",
    "        str: The translated text in the target language.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_recipe(dish_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns a recipe for the given dish name.\n",
    "    Args:\n",
    "        dish_name (str): The name of the dish to get the recipe for.\n",
    "    Returns:\n",
    "        str: A string containing the recipe instructions.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "@tool\n",
    "def solve_math_problem(problem: str) -> str:\n",
    "    \"\"\"\n",
    "    Solves a given math equation using a symbolic math library.\n",
    "    Simply pass in the equation.\n",
    "    Args:\n",
    "        problem (str): The equation to be solved.\n",
    "    Returns:\n",
    "        str: The solution to the equation.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "@tool\n",
    "def send_slack_message(channel_name: str, message: str) -> bool:\n",
    "    \"\"\"\n",
    "    Send a message to a Slack channel.\n",
    "    Args:\n",
    "        channel_name (str): The name of the channel.\n",
    "        message (str): The message to be sent.\n",
    "    Returns:\n",
    "        bool: True if the message was sent successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "functions = [\n",
    "    get_weather_forecast,\n",
    "    book_flight,\n",
    "    book_movie_tickets,\n",
    "    translate_text,\n",
    "    get_recipe,\n",
    "    solve_math_problem,\n",
    "    send_slack_message,\n",
    "]\n",
    "tools = [convert_to_openai_tool(f) for f in functions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaed9e6",
   "metadata": {},
   "source": [
    "Here is an example of two of the tool definitions. Note that this is the **same** `tools` format used by OpenAI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "70d8fb36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:02:07.974470Z",
     "start_time": "2024-03-18T12:02:07.957775Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'type': 'function',\n 'function': {'name': 'get_weather_forecast',\n  'description': \"get_weather_forecast(location: str, date: str) -> str - Provides a weather forecast for a given location and date.\\n\\n    Args:\\n        location (str): The name of the city and state, e.g. 'San Francisco, CA'.\\n        date (str): The date of the forecast in YYYY-MM-DD format, e.g. '2023-07-01'.\\n\\n    Returns:\\n        str: A string containing the weather forecast, e.g. 'Partly cloudy with a high of 72F (22C).'\",\n  'parameters': {'type': 'object',\n   'properties': {'location': {'type': 'string'}, 'date': {'type': 'string'}},\n   'required': ['location', 'date']}}}"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0fcedaf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:02:07.975354Z",
     "start_time": "2024-03-18T12:02:07.961764Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'type': 'function',\n 'function': {'name': 'send_slack_message',\n  'description': 'send_slack_message(channel_name: str, message: str) -> bool - Send a message to a Slack channel.\\n    Args:\\n        channel_name (str): The name of the channel.\\n        message (str): The message to be sent.\\n    Returns:\\n        bool: True if the message was sent successfully, False otherwise.',\n  'parameters': {'type': 'object',\n   'properties': {'channel_name': {'type': 'string'},\n    'message': {'type': 'string'}},\n   'required': ['channel_name', 'message']}}}"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a67acc",
   "metadata": {},
   "source": [
    "Here is a list of questions to test out the function calling capabilities. For each question\n",
    "we have the text and the ground truth expected function name and arguments.\n",
    "This way we can have a mini evaluation for how well the function calling works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "91258229",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:02:07.975405Z",
     "start_time": "2024-03-18T12:02:07.971195Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "    {\n",
    "        \"question\": \"What will the weather be like in Seattle, WA tomorrow?\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"get_weather_forecast\",\n",
    "                \"arguments\": {\n",
    "                    \"location\": \"Seattle, WA\",\n",
    "                    \"date\": (datetime.now() + timedelta(days=1)).strftime(\"%Y-%m-%d\"),\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What's the forecast for Miami for today?\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"get_weather_forecast\",\n",
    "                \"arguments\": {\"location\": \"Miami, FL\", \"date\": datetime.now().strftime(\"%Y-%m-%d\")},\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Will I need an umbrella in New York City two days from now?\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"get_weather_forecast\",\n",
    "                \"arguments\": {\n",
    "                    \"location\": \"New York City, NY\",\n",
    "                    \"date\": (datetime.now() + timedelta(days=2)).strftime(\"%Y-%m-%d\"),\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Book me a round-trip flight from New York City to Los Angeles departing on June 15th and returning June 22nd for 2 passengers in economy class.\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"book_flight\",\n",
    "                \"arguments\": {\n",
    "                    \"departure_city\": \"NYC\",\n",
    "                    \"arrival_city\": \"LAX\",\n",
    "                    \"departure_date\": datetime(datetime.now().year, 6, 15).strftime(\"%Y-%m-%d\"),\n",
    "                    \"return_date\": datetime(datetime.now().year, 6, 22).strftime(\"%Y-%m-%d\"),\n",
    "                    \"num_passengers\": 2,\n",
    "                    \"cabin_class\": \"economy\",\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I need to book a first class round-trip flight for 4 people from Chicago to Miami. We want to leave on December 1 and return on December 12.\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"book_flight\",\n",
    "                \"arguments\": {\n",
    "                    \"departure_city\": \"Chicago\",\n",
    "                    \"arrival_city\": \"Miami\",\n",
    "                    \"departure_date\": datetime(datetime.now().year, 12, 1).strftime(\"%Y-%m-%d\"),\n",
    "                    \"return_date\": datetime(datetime.now().year, 12, 12).strftime(\"%Y-%m-%d\"),\n",
    "                    \"num_passengers\": 4,\n",
    "                    \"cabin_class\": \"first\",\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"I want to book 3 tickets for The Super Mario Bros. Movie at AMC Empire 25 on April 7th at 7:30 PM.\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"book_movie_tickets\",\n",
    "                \"arguments\": {\n",
    "                    \"movie_name\": \"The Super Mario Bros. Movie\",\n",
    "                    \"theater_name\": \"AMC Empire 25\",\n",
    "                    \"date\": datetime(datetime.now().year, 4, 7).strftime(\"%Y-%m-%d\"),\n",
    "                    \"time\": \"19:30\",\n",
    "                    \"num_tickets\": 3,\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Book 2 tickets for Guardians of the Galaxy Vol. 3 at Regal Union Square on May 5th for the 9:45 PM show.\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"book_movie_tickets\",\n",
    "                \"arguments\": {\n",
    "                    \"movie_name\": \"Guardians of the Galaxy Vol. 3\",\n",
    "                    \"theater_name\": \"Regal Union Square\",\n",
    "                    \"date\": datetime(datetime.now().year, 5, 5).strftime(\"%Y-%m-%d\"),\n",
    "                    \"time\": \"21:45\",\n",
    "                    \"num_tickets\": 2,\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do you say 'Hello, how are you?' in Spanish?\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"translate_text\",\n",
    "                \"arguments\": {\"text\": \"Hello, how are you?\", \"target_language\": \"es\"},\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Translate 'I love programming' to French.\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"translate_text\",\n",
    "                \"arguments\": {\"text\": \"I love programming\", \"target_language\": \"fr\"},\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I make pesto?\",\n",
    "        \"tool_calls\": [{\"name\": \"get_recipe\", \"arguments\": {\"dish_name\": \"pesto\"}}],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What's a good vegan chili recipe?\",\n",
    "        \"tool_calls\": [{\"name\": \"get_recipe\", \"arguments\": {\"dish_name\": \"vegan chili\"}}],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Can you give me a recipe for chocolate chip cookies?\",\n",
    "        \"tool_calls\": [{\"name\": \"get_recipe\", \"arguments\": {\"dish_name\": \"chocolate chip cookies\"}}],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Solve the equation: x^2 + 2x + 1=0.\",\n",
    "        \"tool_calls\": [{\"name\": \"solve_math_problem\", \"arguments\": {\"problem\": \"x^2 + 2x + 1=0\"}}],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Solve the equation: 3x - 7 = 5x + 9\",\n",
    "        \"tool_calls\": [{\"name\": \"solve_math_problem\", \"arguments\": {\"problem\": \"3x - 7 = 5x + 9\"}}],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Solve the equation: sin(x) = 0\",\n",
    "        \"tool_calls\": [{\"name\": \"solve_math_problem\", \"arguments\": {\"problem\": \"sin(x) = 0\"}}],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Send a message to the general channel on Slack saying 'Hello, world!'\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"send_slack_message\",\n",
    "                \"arguments\": {\"channel_name\": \"general\", \"message\": \"Hello, world!\"},\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Send a message to the sales-team channel on Slack with the message: 'Please register for the conference.'\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"send_slack_message\",\n",
    "                \"arguments\": {\n",
    "                    \"channel_name\": \"sales-team\",\n",
    "                    \"message\": \"Please register for the conference.\",\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Send a message to the office-updates channel with the message 'FOOD IS HERE!'\",\n",
    "        \"tool_calls\": [\n",
    "            {\n",
    "                \"name\": \"send_slack_message\",\n",
    "                \"arguments\": {\"channel_name\": \"office-updates\", \"message\": \"FOOD IS HERE!\"},\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b3bd6867",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:02:07.989012Z",
     "start_time": "2024-03-18T12:02:07.973588Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random.shuffle(tools)\n",
    "random.shuffle(questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5a01a",
   "metadata": {},
   "source": [
    "## gpt-3.5-turbo-0125 Function Calling\n",
    "\n",
    "First we will use `gpt-3.5-turbo-0125` to extract the function name and arguments for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f5d6e0d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:42:00.518931Z",
     "start_time": "2024-03-18T12:42:00.506333Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_tool_calls(resp):\n",
    "    resp = resp.choices[0].message\n",
    "    if resp.tool_calls:\n",
    "        final_tools = []\n",
    "        for tool_call in resp.tool_calls:\n",
    "            final_tools.append(\n",
    "                {\n",
    "                    \"name\": tool_call.function.name,\n",
    "                    \"arguments\": json.loads(tool_call.function.arguments),\n",
    "                }\n",
    "            )\n",
    "        return final_tools\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aeb781",
   "metadata": {},
   "source": [
    "I'm going to use GPT4 to check the \"correctness\" of the predicted/generated function arguments by comparing them with the expected arguments. \n",
    "This step is completely optional. Instead, you could use exact string matching or something else. I was curious to see how this would work though.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "88c70646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:42:02.525896Z",
     "start_time": "2024-03-18T12:42:02.521958Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_tool_call_arguments(expected, predicted):\n",
    "    # Ask GPT4 if the expected function name and arguments are the same as the predicted  function name and arguments.\n",
    "    if expected[\"name\"] != predicted[\"name\"]:\n",
    "        return False, f'Function Names Do not Match. Expected {expected[\"name\"]}. Predicted: {predicted[\"name\"]}'\n",
    "    prompt = f\"\"\"\n",
    "Check if the following queries are approx equal. Use fuzzy logic matching for strings.\n",
    "Check to see if the arguments are semantically similar, especially for free form text.\n",
    "If you decide they are equivalent then return TRUE and only TRUE with no other explanation. \n",
    "Otherwise return FALSE and give an explanation why they don't match.\n",
    "\n",
    "Expected Arguments: {expected['arguments']}\n",
    "Predicted Arguments: {predicted['arguments']}\n",
    "    \"\"\"\n",
    "    resp = llm(model=\"gpt-4-0125-preview\", messages=[dict(role=\"user\", content=prompt)])\n",
    "    if resp.choices[0].message.content.lower().strip() == \"true\":\n",
    "        return True, None\n",
    "    explanation = resp.choices[0].message.content.lower().strip()\n",
    "    return False, explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fd2276",
   "metadata": {},
   "source": [
    "Okay, let's loop over the questions and use `gpt-3.5-turbo-0125` to extract the function name and arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3cfdc92a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:42:04.047998Z",
     "start_time": "2024-03-18T12:42:04.045142Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_openai_inference_models(model=\"gpt-3.5-turbo-0125\", base_url=None, api_key=None):\n",
    "    total = 0\n",
    "    total_correct = 0\n",
    "    for question in questions:\n",
    "        resp = llm(\n",
    "            api_key=api_key,\n",
    "            base_url=base_url,\n",
    "            model=model,\n",
    "            tools=tools,\n",
    "            messages=[\n",
    "                dict(role=\"system\", content=f\"The date today is {today}\"),\n",
    "                dict(role=\"user\", content=question[\"question\"]),\n",
    "            ],\n",
    "        )\n",
    "        tool_calls = extract_tool_calls(resp)\n",
    "        if tool_calls is None:\n",
    "            print(f'Model {model} failed to return any tool calls for question {question[\"question\"]}')\n",
    "            total += 1\n",
    "            continue\n",
    "        assert len(tool_calls) == len(question[\"tool_calls\"])\n",
    "        for tool_call, expected_call in zip(tool_calls, question[\"tool_calls\"]):\n",
    "            correct_call, explanation = check_tool_call_arguments(expected_call, tool_call)\n",
    "            if not correct_call:\n",
    "                print(f'QUESTION: {question[\"question\"]}')\n",
    "                print(f'EXPECTED Tool Call: {question[\"tool_calls\"][0]}')\n",
    "                print(f\"GENERATED Tool Call: {tool_call}\")\n",
    "                print(f\"EXPLANATION: {explanation}\\n\\n\")\n",
    "            else:\n",
    "                total_correct += 1\n",
    "            total += 1\n",
    "    return total_correct, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2679708e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:19:10.519266Z",
     "start_time": "2024-03-18T12:18:36.935712Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly called the proper functions 18 times out of 18. But check the \"failure\" cases above since they may be correct anyway.\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-3.5-turbo-0125\"\n",
    "total_correct, total = eval_openai_inference_models(model=model, base_url=None, api_key=None)\n",
    "print(\n",
    "    f'Correctly called the proper functions {total_correct} times out of {total}. But check the \"failure\" cases above since they may be correct anyway.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed755506b7bb49",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## gpt-4-0125-preview Function Calling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4110bf0ff338c691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:22:57.486659Z",
     "start_time": "2024-03-18T12:21:46.994091Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION: What's the forecast for Miami for today?\n",
      "EXPECTED Tool Call: {'name': 'get_weather_forecast', 'arguments': {'location': 'Miami, FL', 'date': '2024-03-18'}}\n",
      "GENERATED Tool Call: {'name': 'get_weather_foreast', 'arguments': {'date': '2024-03-18', 'location': 'Miami, FL'}}\n",
      "EXPLANATION: Function Names Do not Match. Expected get_weather_forecast. Predicted: get_weather_foreast\n",
      "\n",
      "Correctly called the proper functions 17 times out of 18. But check the \"failure\" cases above since they may be correct anyway.\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4-0125-preview\"\n",
    "total_correct, total = eval_openai_inference_models(model=model, base_url=None, api_key=None)\n",
    "print(\n",
    "    f'Correctly called the proper functions {total_correct} times out of {total}. But check the \"failure\" cases above since they may be correct anyway.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e4068442985b6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Mistral-7B-Instruct-v0.1 with together.ai Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bd10ee01e25c3a5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:23:37.760185Z",
     "start_time": "2024-03-18T12:22:57.499532Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mistralai/Mistral-7B-Instruct-v0.1 failed to return any tool calls for question How do I make pesto?\n",
      "QUESTION: What's a good vegan chili recipe?\n",
      "EXPECTED Tool Call: {'name': 'get_recipe', 'arguments': {'dish_name': 'vegan chili'}}\n",
      "GENERATED Tool Call: {'name': 'solve_math_problem', 'arguments': {'problem': 'What is the square root of 16?'}}\n",
      "EXPLANATION: Function Names Do not Match. Expected get_recipe. Predicted: solve_math_problem\n",
      "\n",
      "\n",
      "Correctly called the proper functions 16 times out of 18. But check the \"failure\" cases above since they may be correct anyway.\n"
     ]
    }
   ],
   "source": [
    "model = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "total_correct, total = eval_openai_inference_models(model=model, base_url=TOGETHER_AI_BASE_URL, api_key=TOGETHER_API_KEY)\n",
    "print(\n",
    "    f'Correctly called the proper functions {total_correct} times out of {total}. But check the \"failure\" cases above since they may be correct anyway.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6958aedff5d9c419",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## mistralai/Mixtral-8x7B-Instruct-v0.1 with together.ai Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d3e1076577eb82c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:42:57.866098Z",
     "start_time": "2024-03-18T12:42:07.859297Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mistralai/Mixtral-8x7B-Instruct-v0.1 failed to return any tool calls for question How do I make pesto?\n",
      "QUESTION: I need to book a first class round-trip flight for 4 people from Chicago to Miami. We want to leave on December 1 and return on December 12.\n",
      "EXPECTED Tool Call: {'name': 'book_flight', 'arguments': {'departure_city': 'Chicago', 'arrival_city': 'Miami', 'departure_date': '2024-12-01', 'return_date': '2024-12-12', 'num_passengers': 4, 'cabin_class': 'first'}}\n",
      "GENERATED Tool Call: {'name': 'book_flight', 'arguments': {'departure_city': 'Chicago', 'arrival_city': 'Miami', 'departure_date': '2023-12-01', 'return_date': '2023-12-12', 'num_passengers': 4, 'cabin_class': 'first'}}\n",
      "EXPLANATION: false\n",
      "\n",
      "the departure_date and return_date values do not match. the expected arguments have dates in 2024, while the predicted arguments have dates in 2023.\n",
      "\n",
      "QUESTION: Book me a round-trip flight from New York City to Los Angeles departing on June 15th and returning June 22nd for 2 passengers in economy class.\n",
      "EXPECTED Tool Call: {'name': 'book_flight', 'arguments': {'departure_city': 'NYC', 'arrival_city': 'LAX', 'departure_date': '2024-06-15', 'return_date': '2024-06-22', 'num_passengers': 2, 'cabin_class': 'economy'}}\n",
      "GENERATED Tool Call: {'name': 'book_flight', 'arguments': {'departure_city': 'New York City', 'arrival_city': 'Los Angeles', 'departure_date': '2023-06-15', 'return_date': '2023-06-22', 'num_passengers': 2, 'cabin_class': 'economy'}}\n",
      "EXPLANATION: false\n",
      "\n",
      "explanation:\n",
      "- the 'departure_city' and 'arrival_city' fields match semantically as 'nyc' is commonly known as 'new york city' and 'lax' is a well-known shorthand for the los angeles airport, often used to refer to los angeles itself.\n",
      "- the 'departure_date' and 'return_date' do not match. the expected arguments specify a year 2024, while the predicted arguments have the year 2023 for both dates.\n",
      "- the 'num_passengers' and 'cabin_class' fields match exactly in both value and semantics. \n",
      "\n",
      "the primary reason for the non-match is the difference in 'departure_date' and 'return_date' by one year.\n",
      "\n",
      "Correctly called the proper functions 15 times out of 18. But check the \"failure\" cases above since they may be correct anyway.\n"
     ]
    }
   ],
   "source": [
    "model = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "total_correct, total = eval_openai_inference_models(model=model, base_url=TOGETHER_AI_BASE_URL, api_key=TOGETHER_API_KEY)\n",
    "print(\n",
    "    f'Correctly called the proper functions {total_correct} times out of {total}. But check the \"failure\" cases above since they may be correct anyway.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2de5ca3af4aebe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "::: {.callout-warning}\n",
    "## What is going on with together.ai function calling mistakes above\n",
    "Both models had issues with the pesto question. I wonder if this is something on together.ai's end of things and how\n",
    "they implemented this function calling feature. IDK!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d862b",
   "metadata": {},
   "source": [
    "## NousResearch/Hermes-2-Pro-Mistral-7B Function Calling\n",
    "\n",
    "Now we will repeat with `NousResearch/Hermes-2-Pro-Mistral-7B`.\n",
    "The format for the function calling is documented \n",
    "on the [model card](https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B#prompt-format-for-function-calling) as well as in this [repo](https://github.com/NousResearch/Hermes-Function-Calling). The way we define the tools is the same format as with OpenAI.\n",
    "However, we don't pass in a `tools` argument. Rather, we use a special `system` prompt which defines the tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "138fdb01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:34:25.894652Z",
     "start_time": "2024-03-18T12:33:23.341378Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_tool_calls(tool_calls_str):\n",
    "    tool_calls = tool_calls_str.split(\"</tool_call>\\n\")\n",
    "    parsed_results = []\n",
    "    for tool_call in tool_calls:\n",
    "        if tool_call:\n",
    "            dict_str = tool_call.split(\"\\n\")[1]\n",
    "            tool_call_dict = ast.literal_eval(dict_str)\n",
    "            parsed_results.append({\"arguments\": tool_call_dict[\"arguments\"], \"name\": tool_call_dict[\"name\"]})\n",
    "    return parsed_results\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    f\"The date today is {today}\\n\"\n",
    "    + \"\"\"\n",
    "You are a function calling AI model. You are provided with function signatures within <tools></tools> XML tags. You may call one or more functions to assist with the user query. Don't make assumptions about what values to plug into functions. Here are the available tools:\n",
    "<tools> \n",
    "\"\"\"\n",
    "    + str(tools)\n",
    "    + \"\"\"\n",
    "    \n",
    "</tools> Use the following pydantic model json schema for each tool call you will make: {'title': 'FunctionCall', 'type': 'object', 'properties': {'arguments': {'title': 'Arguments', 'type': 'object'}, 'name': {'title': 'Name', 'type': 'string'}}, 'required': ['arguments', 'name']} For each function call return a json object with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "<tool_call>\n",
    "{'arguments': <args-dict>, 'name': <function-name>}\n",
    "</tool_call>\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "total = 0\n",
    "total_correct = 0\n",
    "for question in questions:\n",
    "    resp = llm(\n",
    "        model=\"tgi\",\n",
    "        base_url=HUGGING_FACE_ENDPOINT_URL,\n",
    "        api_key=HUGGING_FACE_ACCESS_TOKEN,\n",
    "        messages=[\n",
    "            dict(role=\"system\", content=system_prompt),\n",
    "            dict(role=\"user\", content=question[\"question\"]),\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "    )\n",
    "    tool_calls = extract_tool_calls(resp.choices[0].message.content)\n",
    "    assert len(tool_calls) == len(question[\"tool_calls\"])\n",
    "    for tool_call, expected_call in zip(tool_calls, question[\"tool_calls\"]):\n",
    "        correct_call, explanation = check_tool_call_arguments(expected_call, tool_call)\n",
    "        if not correct_call:\n",
    "            print(f'QUESTION: {question[\"question\"]}')\n",
    "            print(f'EXPECTED Tool Call: {question[\"tool_calls\"][0]}')\n",
    "            print(f\"GENERATED Tool Call: {tool_call}\")\n",
    "            print(f\"EXPLANATION: {explanation}\\n\\n\")\n",
    "        else:\n",
    "            total_correct += 1\n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1140af10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-18T12:34:25.900525Z",
     "start_time": "2024-03-18T12:34:25.896337Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly called the proper functions 18 times out of 18. But check the \"failure\" cases above since they may be correct anyway.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f'Correctly called the proper functions {total_correct} times out of {total}. But check the \"failure\" cases above since they may be correct anyway.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f05dcd",
   "metadata": {},
   "source": [
    "Wow, it got all of them correct! It may not get them all correct every time. Run it over again to see if any mistakes are made.\n",
    "Sometimes I saw it forgetting to fill in `num_tickets` for example.\n",
    "\n",
    "Let's look at a single question to see the output from the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0724d572",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:36:10.930090Z",
     "start_time": "2024-03-16T23:36:10.913473Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'Saturday 2024-03-16'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8d3c9d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:36:11.872955Z",
     "start_time": "2024-03-16T23:36:11.866655Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "question = \"I want to go see Dune 2 on Wednesday night with 5 of my friends. We will be going to the Halifax Bayers Lake Ciniplex Theatre. Get tickets for the 7pm show. Thanks!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91f82dc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:36:17.980404Z",
     "start_time": "2024-03-16T23:36:14.011247Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "ChatCompletion(id='', choices=[Choice(finish_reason='eos_token', index=0, logprobs=None, message=ChatCompletionMessage(content=\"<tool_call>\\n{'arguments': {'movie_name': 'Dune 2', 'theater_name': 'Halifax Bayers Lake Ciniplex Theatre', 'date': '2024-03-20', 'time': '19:00', 'num_tickets': 6}, 'name': 'book_movie_tickets'}\\n</tool_call>\\n\", role='assistant', function_call=None, tool_calls=None, name=None))], created=1710632177, model='/repository', object='text_completion', system_fingerprint='1.4.1-native', usage=CompletionUsage(completion_tokens=93, prompt_tokens=1719, total_tokens=1812))"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = llm(\n",
    "    model=\"tgi\",\n",
    "    base_url=HUGGING_FACE_ENDPOINT_URL,\n",
    "    api_key=HUGGING_FACE_ACCESS_TOKEN,\n",
    "    messages=[\n",
    "        dict(role=\"system\", content=system_prompt),\n",
    "        dict(role=\"user\", content=question),\n",
    "    ],\n",
    ")\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d2a1d5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:36:17.994172Z",
     "start_time": "2024-03-16T23:36:17.977790Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tool_call>\n",
      "{'arguments': {'movie_name': 'Dune 2', 'theater_name': 'Halifax Bayers Lake Ciniplex Theatre', 'date': '2024-03-20', 'time': '19:00', 'num_tickets': 6}, 'name': 'book_movie_tickets'}\n",
      "</tool_call>\n"
     ]
    }
   ],
   "source": [
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a09891f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:36:18.597404Z",
     "start_time": "2024-03-16T23:36:18.584415Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'arguments': {'movie_name': 'Dune 2',\n   'theater_name': 'Halifax Bayers Lake Ciniplex Theatre',\n   'date': '2024-03-20',\n   'time': '19:00',\n   'num_tickets': 6},\n  'name': 'book_movie_tickets'}]"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls = extract_tool_calls(resp.choices[0].message.content)\n",
    "tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f0475",
   "metadata": {},
   "source": [
    "The model also supports multiple function calls!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b3e019a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:38:55.126485Z",
     "start_time": "2024-03-16T23:38:55.122847Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tasks = f\"\"\"\n",
    "Today's date is {today}.\n",
    "\n",
    "Please complete the following tasks for me:\n",
    "\n",
    "1. I want to go see Dune 2 on Monday night with 5 of my friends. We will be going to the Halifax Bayers Lake Ciniplex Theatre. Get tickets for the 7pm show.\n",
    "\n",
    "2. Please check the weather for Monday night so I know how to dress.\n",
    "\n",
    "3. Also please book my plane ticket to Toronto. I will be leaving Tuesday and coming back 2 days later on Thursday. First class please.\n",
    "\n",
    "4. Send a slack message to the research channel to let them know I will not be there this week in the office.\n",
    " \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "26d8b6e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-16T23:39:06.227116Z",
     "start_time": "2024-03-16T23:38:55.540201Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'arguments': {'movie_name': 'Dune 2',\n   'theater_name': 'Halifax Bayers Lake Ciniplex Theatre',\n   'date': '2024-03-18',\n   'time': '19:00',\n   'num_tickets': 6},\n  'name': 'book_movie_tickets'},\n {'arguments': {'location': 'Halifax Bayers Lake', 'date': '2024-03-18'},\n  'name': 'get_weather_forecast'},\n {'arguments': {'departure_city': 'Halifax',\n   'arrival_city': 'Toronto',\n   'departure_date': '2024-03-19',\n   'return_date': '2024-03-21',\n   'num_passengers': 1,\n   'cabin_class': 'first'},\n  'name': 'book_flight'},\n {'arguments': {'channel_name': 'research',\n   'message': 'I will not be in the office this week.'},\n  'name': 'send_slack_message'}]"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = llm(\n",
    "    model=\"tgi\",\n",
    "    base_url=HUGGING_FACE_ENDPOINT_URL,\n",
    "    api_key=HUGGING_FACE_ACCESS_TOKEN,\n",
    "    messages=[\n",
    "        dict(role=\"system\", content=system_prompt),\n",
    "        dict(role=\"user\", content=tasks),\n",
    "    ],\n",
    "    max_tokens=1000,\n",
    ")\n",
    "tool_calls = extract_tool_calls(resp.choices[0].message.content)\n",
    "tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6004cada",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Impressive!\n",
    "\n",
    "You can take the arguments, and pass them into the actual function, and give back the results to the model.\n",
    "See the [model card](https://huggingface.co/NousResearch/Hermes-2-Pro-Mistral-7B#prompt-format-for-function-calling) or [repo](https://github.com/NousResearch/Hermes-Function-Calling) on how to do that.\n",
    "\n",
    "There is JSON Mode support too!\n",
    "\n",
    "I'm just getting started with playing around with this powerful open source model. I can't wait to explore it more!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
