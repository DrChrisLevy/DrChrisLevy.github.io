{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e6ef388af5e47b7d",
   "metadata": {
    "collapsed": false,
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Intro to LLMs\"\n",
    "subtitle: \"Lunch and Learn Talk\"\n",
    "author: \"Chris Levy\"\n",
    "date: '2024-05-01'\n",
    "date-modified: '2024-05-01'\n",
    "image: attention-transformer-paper1.png\n",
    "description: In this lunch and learn presentation I provide an introduction to LLMs for developers covering topics such as NLP history, word embeddings, transformer architecture, tokenization, base vs. instruction models, OpenAI-compatible inference, chat templates, structured output, function calling, RAG, multimodal capabilities, code interpreter, and fine-tuning.\n",
    "tags:\n",
    "  - llms\n",
    "  - transformers\n",
    "  - OpenAI\n",
    "  - RAG\n",
    "  - Fine-tuning\n",
    "format:\n",
    "  revealjs:\n",
    "    incremental: false\n",
    "    scrollable: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fd71c3ac47b0073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:14:56.074610Z",
     "start_time": "2024-04-30T23:14:55.824442Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | output: false\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899eca7a4b1eb33",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ENV Setup {.smaller}\n",
    "\n",
    "- create a virtual env\n",
    "```\n",
    "python3 -m venv env\n",
    "source env/bin/activate\n",
    "```\n",
    "\n",
    "- install packages\n",
    "```\n",
    "pip install tiktoken\n",
    "pip install openai\n",
    "pip install instructor\n",
    "pip install transformers\n",
    "pip install torch\n",
    "pip install python-dotenv\n",
    "pip install notebook\n",
    "```\n",
    "\n",
    "- add env vars in .env file\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=<key>\n",
    "TOGETHER_API_KEY=<key>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225040d3de0f79fb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Background\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3052959ed8af4ae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## NLP Through The Years  {.smaller}\n",
    "\n",
    "- [ELIZA (MIT),1964-1967](https://en.wikipedia.org/wiki/ELIZA#Response_and_legacy), [CS25 V4: Lecture 1 (Spring 2024)](https://docs.google.com/presentation/d/1oXPs3LXtIVIsVbwTyGjAWj_aWvak9c1uNC4uhkS6glk/edit#slide=id.gea1aecfd7b_0_0)\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "![](static_blog_imgs/eliza.png){height=20%, width=80%}\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "![](static_blog_imgs/timeline.png){height=60%, width=80%}\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "## Word Embeddings {.smaller}\n",
    "- represent each word as an embedding (vector of numbers)\n",
    "- useful computations such as distance (cosine/euclidean)\n",
    "- mapping of words onto a semantic space\n",
    "- example: Word2Vec (2013), GloVe, BERT, ELMo\n",
    "\n",
    "![](static_blog_imgs/word-vectors.png)\n",
    "\n",
    "\n",
    "## Attention and Transformers\n",
    "\n",
    "- [Image Source: nlp-with-transformers book](https://github.com/nlp-with-transformers/notebooks/blob/main/03_transformer-anatomy.ipynb)\n",
    "\n",
    "![](static_blog_imgs/self-attention.png){height=60%,width=60%}\n",
    "\n",
    "\n",
    "## Transformer & Multi-Head Attention\n",
    "\n",
    "\n",
    "- [Attention Is All you Need: Paper](https://arxiv.org/pdf/1706.03762.pdf)\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "![](static_blog_imgs/attention-transformer-paper1.png){height=70%, width=70%}\n",
    ":::\n",
    "\n",
    "::: {.column width=\"50%\"}\n",
    "![](static_blog_imgs/attention-transformer-paper2.png)\n",
    ":::\n",
    "\n",
    "::::\n",
    "\n",
    "\n",
    "## What is a LLM (large language model)?\n",
    "\n",
    "- LLMs are scaled up versions of the Transformer architecture (millions/billions of parameters)\n",
    "- Most modern LLMs are **decoder only transformers**\n",
    "- Trained on massive amounts of ‚Äúgeneral‚Äù textual data\n",
    "- Training objective is typically ‚Äúnext token prediction‚Äù: P(Wt+1|Wt,Wt-1,...,W1)\n",
    "\n",
    "\n",
    "## Next Token Prediction\n",
    "\n",
    " - LLMs are next token predictors\n",
    "- \"It is raining today, so I will take my _______.\" \n",
    "\n",
    "![](static_blog_imgs/next_token1.png)\n",
    "\n",
    "![](static_blog_imgs/next_token2.png)\n",
    "\n",
    "\n",
    "## Tokenization with tiktoken library {.smaller}\n",
    "\n",
    "- The first step is to convert the input text into **tokens**\n",
    "- Each **token** has an id in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc244b86baccdff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:14:56.202692Z",
     "start_time": "2024-04-30T23:14:55.850498Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83, 1609, 5963, 374, 2294, 0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4-0125\")\n",
    "encoded_text = enc.encode(\"tiktoken is great!\")\n",
    "encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a147b20f69d4df2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:14:56.204961Z",
     "start_time": "2024-04-30T23:14:56.070180Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'ik', 'token', ' is', ' great', '!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "[enc.decode([token]) for token in encoded_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c005a52f564754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:14:56.213894Z",
     "start_time": "2024-04-30T23:14:56.076343Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiktoken is great!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "enc.decode([83, 1609, 5963, 374, 2294, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3152e86b5eb92e4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "## Tokenization with transformers library {.smaller}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efca49baefc177c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:14:58.055428Z",
     "start_time": "2024-04-30T23:14:56.080789Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopher/personal_projects/DrChrisLevy.github.io/posts/llm_talk/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1045,  2293,  2621,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2293, 11937, 13186,   102,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]])\n",
      "torch.Size([2, 16])\n",
      "30522\n",
      "['[CLS]', 'i', 'love', 'summer', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "['[CLS]', 'i', 'love', 'ta', '##cos', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "# | warning: false\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "texts = [\n",
    "    \"I love summer\",\n",
    "    \"I love tacos\",\n",
    "]\n",
    "inputs = tokenizer(\n",
    "    texts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    max_length=16,\n",
    "    truncation=True,\n",
    ").input_ids\n",
    "print(inputs)\n",
    "\n",
    "print(inputs.shape)  # (B, T)\n",
    "print(tokenizer.vocab_size)\n",
    "for row in inputs:\n",
    "    print(tokenizer.convert_ids_to_tokens(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b837d7d196ff7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Tokenization is the First Step {.smaller}\n",
    "\n",
    "![](static_blog_imgs/first_step.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262cc254af43e0a4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## LLMS are not great at math. Why? {.smaller}\n",
    "\n",
    "- because of tokenization and next token prediction\n",
    "\n",
    "What is the average of:  2009 1746 4824 8439\n",
    "\n",
    "![](static_blog_imgs/llms_suck_at_math.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ab54cd8ab55645",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:14:58.059277Z",
     "start_time": "2024-04-30T23:14:58.056574Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3923, 374, 279, 5578, 315, 25, 220, 220, 1049, 24, 220, 11771, 21, 220, 21984, 19, 220, 23996, 24]\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "encoded_text = enc.encode(\"What is the average of:  2009 1746 4824 8439\")\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2799e2f0ccad18d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:14:58.062900Z",
     "start_time": "2024-04-30T23:14:58.059913Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', ' is', ' the', ' average', ' of', ':', ' ', ' ', '200', '9', ' ', '174', '6', ' ', '482', '4', ' ', '843', '9']\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "print([enc.decode([token]) for token in encoded_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e89d2e678dc499",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Basic Transformer Architecture - Futher Reading {.smaller}\n",
    "- Lots of resources online\n",
    "- Some of the ones I enjoyed while learning:\n",
    "    - Chapter 3 of the book [Natural Language Processing With Transformers](https://www.oreilly.com/library/view/natural-language-processing/9781098136789/) \n",
    "    - Andrej Karpathy's video [Let's build GPT: from scratch, in code, spelled out](https://www.youtube.com/watch?v=kCc8FmEb1nY) \n",
    "    - Sebastian Raschka's Blog Post [Understanding and Coding Self-Attention, Multi-Head Attention, Cross-Attention, and Causal-Attention in LLMs](https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention) \n",
    "    - Omar Sanseviero's Blog Post [The Random Transformer](https://osanseviero.github.io/hackerllama/blog/posts/random_transformer/) \n",
    "    - [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/) \n",
    "    - The original paper: [Attention Is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ee7e9c62e378b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Instruction Models\n",
    "\n",
    "## Base Models VS Instruct Models {.smaller}\n",
    "\n",
    "- `meta-llama/Meta-Llama-3-8B` (base model)\n",
    "\n",
    "![](static_blog_imgs/base_model_example.png)\n",
    "\n",
    "## Base Models VS Instruct Models {.smaller}\n",
    "\n",
    "- `meta-llama/Meta-Llama-3-8B-Instruct`\n",
    "\n",
    "![](static_blog_imgs/instruct_model_example.png)\n",
    "\n",
    "## Popular Instruction Fine-Tuned LLMs {.smaller}\n",
    "\n",
    "- closed\n",
    "    - [Open AI](https://platform.openai.com/docs/models): `gpt-4-turbo-2024-04-09`, `gpt-3.5-turbo-0125`, etc.\n",
    "    - [Anthropic](https://docs.anthropic.com/claude/docs/models-overview): `opus`, `sonnet`, `haiku`\n",
    "    - [Google](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/), `Gemini 1.5`\n",
    "- open\n",
    "    - [Meta](https://llama.meta.com/llama3/): `Llama-3-8B-Instruct`, `Llama-3-70B-Instruct`\n",
    "    - [Mistral](https://mistral.ai/technology/#models): `Mistral 7B`, `Mixtral 8x7B`, `Mixtral 8x22B`\n",
    "    - [Qwen](https://github.com/QwenLM/Qwen): `Qwen-1.8B`, `Qwen-7B`, `Qwen-14B`, `Qwen-72B`\n",
    "    - [HuggingFace](https://huggingface.co/HuggingFaceH4): `Zephyr-ORPO-141b-A35b-v0.1`\n",
    "    - [Databricks](DBRX-Instruct-Preview): `DBRX-Instruct-Preview`\n",
    "    - [NousResearch](https://nousresearch.com/releases/): `Hermes-2-Pro-Mistral-7B`, \n",
    "    - [Cohere](https://docs.cohere.com/docs/command-r-plus): `Command R+`\n",
    "\n",
    " \n",
    "## The Gap is closing {.smaller}\n",
    "\n",
    "- [image source - Maxime Labonne](https://x.com/maximelabonne/status/1779801605702836454), [üèÜ LMSYS Chatbot Arena](https://chat.lmsys.org/?leaderboard)\n",
    "- [another fun animation](https://x.com/jannchie/status/1784621770018058651)\n",
    "![](static_blog_imgs/closed_vs_open.png)\n",
    "\n",
    "## Aligning language models \n",
    "\n",
    "- There is so much theory/research behind creating instruction models\n",
    "- Not going to cover that here\n",
    "- [Checkout this recent talk, Aligning open language models, from Nathan Lambert](https://docs.google.com/presentation/d/1quMyI4BAx4rvcDfk8jjv063bmHg4RxZd9mhQloXpMn0/edit#slide=id.g2ca00c5c0f9_0_0)\n",
    "- [State of GPT Keynote By Andrej Karpathy](https://www.youtube.com/watch?v=bZQun8Y4L2A)\n",
    "- [Large Language Model Course by Maxime Labonne](https://github.com/mlabonne/llm-course)\n",
    "\n",
    "\n",
    "# OpenAI Compatible LLM Inference\n",
    "\n",
    "## OpenAI Compatible LLM Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18455bba38a4daf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:14:59.505405Z",
     "start_time": "2024-04-30T23:14:58.061916Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main characters from Lord of the Rings are Frodo Baggins, Samwise Gamgee, Aragorn, Legolas, Gimli, Gandalf, Boromir, Merry and Pippin, and Gollum.\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Who are the main characters from Lord of the Rings?.\"},\n",
    "    ],\n",
    ")\n",
    "response = chat_completion.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed143a7a46928ad3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## OpenAI Compatible LLM Inference\n",
    "\n",
    "- [together.ai](https://www.together.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f000f49c18c91818",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```{.python code-line-numbers=\"3,5\"}\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=os.environ.get(\"TOGETHER_API_KEY\"), base_url=\"https://api.together.xyz/v1\")\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"META-LLAMA/LLAMA-3-70B-CHAT-HF\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Who are the main characters from Lord of the Rings?.\"},\n",
    "    ],\n",
    ")\n",
    "response = chat_completion.choices[0].message.content\n",
    "print(response)\n",
    "```\n",
    "\n",
    "## OpenAI Compatible LLM Inference {.smaller}\n",
    "\n",
    "- [together.ai](https://www.together.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76241f3f6469eed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:15:04.323267Z",
     "start_time": "2024-04-30T23:14:59.505704Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main characters from J.R.R. Tolkien's epic fantasy novel \"The Lord of the Rings\" are:\n",
      "\n",
      "1. **Frodo Baggins**: The hobbit who inherits the One Ring from Bilbo Baggins and undertakes the perilous journey to destroy it in the fires of Mount Doom.\n",
      "2. **Samwise Gamgee** (Sam): Frodo's loyal hobbit servant and friend, who accompanies him on his quest.\n",
      "3. **Aragorn (Strider)**: A human warrior who becomes the leader of the Fellowship of the Ring and helps guide Frodo on his journey. He is the rightful King of Gondor.\n",
      "4. **Legolas**: An elf archer who joins the Fellowship and provides skilled marksmanship and agility.\n",
      "5. **Gimli**: A dwarf warrior who joins the Fellowship and provides strength and combat skills.\n",
      "6. **Gandalf the Grey**: A powerful wizard who helps guide Frodo on his quest and provides wisdom and magical assistance.\n",
      "7. **Boromir**: A human warrior from the land of Gondor, who joins the Fellowship but ultimately tries to take the Ring from Frodo.\n",
      "8. **Merry Brandybuck** and **Pippin Took**: Frodo's hobbit cousins, who join the Fellowship and provide comic relief and bravery in the face of danger.\n",
      "9. **Sauron**: The primary antagonist, a dark lord who created the One Ring and seeks to conquer Middle-earth.\n",
      "10. **Saruman**: A wizard who betrays Gandalf and allies himself with Sauron, seeking to gain power and control over Middle-earth.\n",
      "\n",
      "These characters form the core of the story, and their interactions and relationships drive the plot of \"The Lord of the Rings\".\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=os.environ.get(\"TOGETHER_API_KEY\"), base_url=\"https://api.together.xyz/v1\")\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"META-LLAMA/LLAMA-3-70B-CHAT-HF\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Who are the main characters from Lord of the Rings?.\"},\n",
    "    ],\n",
    ")\n",
    "response = chat_completion.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43e56397f2afe58",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## OpenAI Compatible LLM Inference {.smaller}\n",
    "\n",
    "- local inference with [ollama](https://ollama.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "542e7984b7756e63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:15:22.195834Z",
     "start_time": "2024-04-30T23:15:04.323425Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main characters in J.R.R. Tolkien's \"Lord of the Rings\" trilogy, which includes \"The Fellowship of the Ring\", \"The Two Towers\", and \"The Return of the King\", are:\n",
      "\n",
      "1. Frodo Baggins: The hobbit who inherits the One Ring from Bilbo and sets out on a quest to destroy it in the fires of Mount Doom.\n",
      "2. Samwise Gamgee (Sam): Frodo's loyal hobbit servant and friend, who accompanies him on his journey to Mordor.\n",
      "3. Aragorn (Strider): A human warrior who leads the Fellowship and helps them navigate the perilous lands of Middle-earth.\n",
      "4. Legolas: An elf archer who joins the Fellowship and fights alongside them against Sauron's armies.\n",
      "5. Gimli: A dwarf warrior who also joins the Fellowship, seeking to avenge his father's death at the hands of orcs.\n",
      "6. Boromir: The human son of the Steward of Gondor, who tries to take the One Ring from Frodo for the benefit of his own people.\n",
      "7. Meriadoc Brandybuck (Merry) and Peregrin Took (Pippin): Two hobbit friends of Frodo's who accompany him on his journey and become embroiled in the quest to destroy the Ring.\n",
      "\n",
      "These characters, along with Gandalf the Grey, a powerful wizard, and other supporting characters, drive the story and its themes of friendship, sacrifice, and the struggle against evil.\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI(api_key=\"ollama\", base_url=\"http://localhost:11434/v1\")\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"llama3\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Who are the main characters from Lord of the Rings?.\"},\n",
    "    ],\n",
    ")\n",
    "response = chat_completion.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6968ccacd790f7b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Chat Templates {.smaller}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d8ded672b1c0478",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:15:22.441153Z",
     "start_time": "2024-04-30T23:15:22.198330Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "# | warning: false\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e765ded0e64898",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- Each model has its own expected input format. For Llama3 it's this:\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "You are a friendly chatbot who always responds in the style of a pirate<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "How many helicopters can a human eat in one sitting?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "- With chat templates we can use this familiar standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a09bd0ffc466505",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:15:22.497923Z",
     "start_time": "2024-04-30T23:15:22.440908Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a friendly chatbot who always responds in the style of a pirate<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "How many helicopters can a human eat in one sitting?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "# | warning: false\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    "]\n",
    "tokenized_chat = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "print(tokenizer.decode(tokenized_chat[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69feb36255f1f9d2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Structured Output\n",
    "\n",
    "## Structured Output {.smaller}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f05a3e15368809",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:15:27.339931Z",
     "start_time": "2024-04-30T23:15:22.468544Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Frodo Baggins\n",
      "- Race: Hobbit\n",
      "- Favorite food: Mushrooms\n",
      "- Skills: Determination, stealth, resilience\n",
      "- Weapons: Sting (his sword)\n",
      "- Fun fact: Frodo is the only character to have directly interacted with the One Ring and survived its corrupting influence.\n",
      "\n",
      "2. Aragorn (also known as Strider)\n",
      "- Race: Human (Dunedain)\n",
      "- Favorite food: Lembas bread\n",
      "- Skills: Swordsmanship, tracking, leadership\n",
      "- Weapons: Anduril (his sword), bow and arrows\n",
      "- Fun fact: Aragorn is the heir to the throne of Gondor and the rightful King of Arnor.\n",
      "\n",
      "3. Gandalf\n",
      "- Race: Maia (wizard)\n",
      "- Favorite food: Pipe-weed\n",
      "- Skills: Magic, wisdom, leadership\n",
      "- Weapons: Glamdring (his sword), staff\n",
      "- Fun fact: Gandalf is actually one of the Maiar, a group of powerful beings who serve the Valar (gods) in the world of Middle-earth.\n",
      "\n",
      "4. Legolas\n",
      "- Race: Elf\n",
      "- Favorite food: Waybread (Lembas)\n",
      "- Skills: Archery, agility, keen eyesight\n",
      "- Weapons: Bow and arrows, knives\n",
      "- Fun fact: Legolas is the son of Thranduil, the Elven King of the Woodland Realm in Mirkwood.\n",
      "\n",
      "5. Gimli\n",
      "- Race: Dwarf\n",
      "- Favorite food: Roast meats\n",
      "- Skills: Axe-fighting, mining, loyalty\n",
      "- Weapons: Axe, throwing axes\n",
      "- Fun fact: Gimli is a member of the Fellowship representing the Dwarves, who are known for their craftsmanship and love of gold and jewels.\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who are the main characters from Lord of the Rings?. \"\n",
    "            \"For each character give the name, race, \"\n",
    "            \"favorite food, skills, weapons, and a fun fact.\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "response = chat_completion.choices[0].message.content\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3dde2c992398ce8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:15:27.346464Z",
     "start_time": "2024-04-30T23:15:27.341654Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b53c46d5e35f50f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Structured Output {.smaller}\n",
    "\n",
    "- [JSON mode](https://platform.openai.com/docs/guides/text-generation/json-mode) and [Function Calling](https://platform.openai.com/docs/guides/function-calling) give us structured output\n",
    "- [instructor - library](https://github.com/jxnl/instructor) - [\"Pydantic is all you need\"](https://www.youtube.com/watch?v=yj-wSRJwrrc)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca2c99a97e2a9854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:15:28.054711Z",
     "start_time": "2024-04-30T23:15:27.349766Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Chris', 'age': 38}\n",
      "Chris\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "import instructor\n",
    "import openai\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = instructor.from_openai(openai.OpenAI())\n",
    "\n",
    "\n",
    "# Define your desired output structure\n",
    "class UserInfo(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    response_model=UserInfo,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Chris is 38 years old.\"}],\n",
    ")\n",
    "print(user_info.model_dump())\n",
    "print(user_info.name)\n",
    "print(user_info.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267859b07181ed9c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Structured Output {.smaller}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b10a069baaa1d3bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:15:28.067840Z",
     "start_time": "2024-04-30T23:15:28.056823Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# | echo: true\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import instructor\n",
    "import openai\n",
    "from pydantic import BaseModel, field_validator\n",
    "\n",
    "client = instructor.from_openai(openai.OpenAI())\n",
    "\n",
    "\n",
    "class Character(BaseModel):\n",
    "    name: str\n",
    "    race: str\n",
    "    fun_fact: str\n",
    "    favorite_food: str\n",
    "    skills: List[str]\n",
    "    weapons: List[str]\n",
    "\n",
    "\n",
    "class Characters(BaseModel):\n",
    "    characters: List[Character]\n",
    "\n",
    "    @field_validator(\"characters\")\n",
    "    @classmethod\n",
    "    def validate_characters(cls, v):\n",
    "        if len(v) < 10:\n",
    "            raise ValueError(f\"The number of characters must be at least 10, but it is {len(v)}\")\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ab10863fab3e6ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:15:35.427043Z",
     "start_time": "2024-04-30T23:15:28.072249Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'characters': [{'favorite_food': 'Mushrooms',\n",
      "                 'fun_fact': 'Frodo is the nephew of Bilbo Baggins.',\n",
      "                 'name': 'Frodo Baggins',\n",
      "                 'race': 'Hobbit',\n",
      "                 'skills': ['Ringbearer', 'Stealth', 'Courage'],\n",
      "                 'weapons': ['Sting', 'Phial of Galadriel']},\n",
      "                {'favorite_food': 'Lembas bread',\n",
      "                 'fun_fact': 'Aragorn is the rightful heir to the throne of '\n",
      "                             'Gondor.',\n",
      "                 'name': 'Aragorn',\n",
      "                 'race': 'Man',\n",
      "                 'skills': ['Swordsmanship', 'Leadership', 'Tracking'],\n",
      "                 'weapons': ['Anduril', 'Bow and Arrow']},\n",
      "                {'favorite_food': 'Roast Pork',\n",
      "                 'fun_fact': 'Gimli is the son of Gloin, one of the Dwarves in '\n",
      "                             \"'The Hobbit'.\",\n",
      "                 'name': 'Gimli',\n",
      "                 'race': 'Dwarf',\n",
      "                 'skills': ['Axe throwing', 'Smithing', 'Courage'],\n",
      "                 'weapons': ['Axe', 'Throwing Axe']},\n",
      "                {'favorite_food': 'Lembas bread',\n",
      "                 'fun_fact': 'Legolas has keen eyesight and can spot enemies '\n",
      "                             'from great distances.',\n",
      "                 'name': 'Legolas',\n",
      "                 'race': 'Elf',\n",
      "                 'skills': ['Archery', 'Agility', 'Sight'],\n",
      "                 'weapons': ['Bow', 'Arrow']},\n",
      "                {'favorite_food': 'Pipe-weed',\n",
      "                 'fun_fact': 'Gandalf is also known as Mithrandir in Elvish.',\n",
      "                 'name': 'Gandalf',\n",
      "                 'race': 'Maia',\n",
      "                 'skills': ['Wizardry', 'Wisdom', 'Combat'],\n",
      "                 'weapons': ['Glamdring', 'Staff']},\n",
      "                {'favorite_food': 'Venison',\n",
      "                 'fun_fact': 'Boromir hails from the realm of Gondor.',\n",
      "                 'name': 'Boromir',\n",
      "                 'race': 'Man',\n",
      "                 'skills': ['Swordsmanship', 'Leadership', 'Athletics'],\n",
      "                 'weapons': ['Sword', 'Shield']},\n",
      "                {'favorite_food': 'Potatoes',\n",
      "                 'fun_fact': 'Sam is known for his unwavering loyalty to '\n",
      "                             'Frodo.',\n",
      "                 'name': 'Samwise Gamgee',\n",
      "                 'race': 'Hobbit',\n",
      "                 'skills': ['Gardening', 'Loyalty', 'Cooking'],\n",
      "                 'weapons': ['Cooking pot', 'Gardening tools']},\n",
      "                {'favorite_food': 'Berry tarts',\n",
      "                 'fun_fact': 'Arwen is the daughter of Elrond, Lord of '\n",
      "                             'Rivendell.',\n",
      "                 'name': 'Arwen',\n",
      "                 'race': 'Half-Elf',\n",
      "                 'skills': ['Horseback riding', 'Healing', 'Sword fighting'],\n",
      "                 'weapons': ['Sword']},\n",
      "                {'favorite_food': 'Apple pie',\n",
      "                 'fun_fact': \"Merry is one of Frodo's close friends and part \"\n",
      "                             'of the Fellowship of the Ring.',\n",
      "                 'name': 'Merry Brandybuck',\n",
      "                 'race': 'Hobbit',\n",
      "                 'skills': ['Stealth', 'Swordsmanship', 'Cooking'],\n",
      "                 'weapons': ['Dagger', 'Sword']},\n",
      "                {'favorite_food': 'Mushrooms',\n",
      "                 'fun_fact': 'Pippin becomes a Knight of Gondor for his '\n",
      "                             'bravery in battle.',\n",
      "                 'name': 'Pippin Took',\n",
      "                 'race': 'Hobbit',\n",
      "                 'skills': ['Loyalty', 'Entertainment', 'Courage'],\n",
      "                 'weapons': ['Dagger', 'Sword']}]}\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who are the main characters from Lord of the Rings?. \"\n",
    "            \"For each character give the name, race, \"\n",
    "            \"favorite food, skills, weapons, and a fun fact. Give me at least 10 different characters.\",\n",
    "        },\n",
    "    ],\n",
    "    response_model=Characters,\n",
    "    max_retries=4,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(response.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fa7c27292d3aa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Function Calling {.smaller}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9910e039a91eb486",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:15:58.998954Z",
     "start_time": "2024-04-30T23:15:35.430315Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function name: book_flight\n",
      "function arguments: {'departure_city': 'Halifax', 'arrival_city': 'Austin', 'departure_date': '2024-05-03', 'return_date': '2024-05-05', 'num_passengers': 2, 'cabin_class': 'First'}\n",
      "\n",
      "function name: get_weather_forecast\n",
      "function arguments: {'location': 'Austin, Texas', 'date': '2024-05-03'}\n",
      "\n",
      "function name: get_weather_forecast\n",
      "function arguments: {'location': 'Austin, Texas', 'date': '2024-05-04'}\n",
      "\n",
      "function name: get_weather_forecast\n",
      "function arguments: {'location': 'Austin, Texas', 'date': '2024-05-05'}\n",
      "\n",
      "function name: send_slack_message\n",
      "function arguments: {'channel_name': 'DEV', 'message': 'I will be out of office this Friday, May 3, 2024. Please reach out via email if urgent.'}\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weather_forecast\",\n",
    "            \"description\": \"Provides a weather forecast for a given location and date.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"location\": {\"type\": \"string\"}, \"date\": {\"type\": \"string\"}},\n",
    "                \"required\": [\"location\", \"date\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"book_flight\",\n",
    "            \"description\": \"Book a flight.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"departure_city\": {\"type\": \"string\"},\n",
    "                    \"arrival_city\": {\"type\": \"string\"},\n",
    "                    \"departure_date\": {\"type\": \"string\"},\n",
    "                    \"return_date\": {\"type\": \"string\"},\n",
    "                    \"num_passengers\": {\"type\": \"integer\"},\n",
    "                    \"cabin_class\": {\"type\": \"string\"},\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"departure_city\",\n",
    "                    \"arrival_city\",\n",
    "                    \"departure_date\",\n",
    "                    \"return_date\",\n",
    "                    \"num_passengers\",\n",
    "                    \"cabin_class\",\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"send_slack_message\",\n",
    "            \"description\": \"Send a slack message to specific channel.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"channel_name\": {\"type\": \"string\"}, \"message\": {\"type\": \"string\"}},\n",
    "                \"required\": [\"channel_name\", \"message\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "import json\n",
    "from datetime import date\n",
    "\n",
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"Today's date is {date.today()}\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\"This coming Friday I need to book a flight from Halifax, NS to Austin, Texas. \n",
    "                                    It will be me and my friend and we need first class seats. \n",
    "                                    We will come back on Sunday. Let me know what I should pack for clothes \n",
    "                                    according to the weather there each day. Also please remind my team on \n",
    "                                    the DEV slack channel that I will be out of office on Friday. \n",
    "                                    1. Book the flight. \n",
    "                                    2. Let me know the weather. \n",
    "                                    3. Send the slack message.\"\"\",\n",
    "        },\n",
    "    ],\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "for tool in chat_completion.choices[0].message.tool_calls:\n",
    "    print(f\"function name: {tool.function.name}\")\n",
    "    print(f\"function arguments: {json.loads(tool.function.arguments)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab112e37586bfa8c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# RAG: Retrieval Augmented Generation {.smaller}\n",
    "\n",
    "## RAG: Step 1 - Index your Documents {.smaller}\n",
    "\n",
    "- RAG is a technique for augmenting LLM knowledge with additional data.\n",
    "- image source: [langchain docs](https://python.langchain.com/docs/use_cases/question_answering/)\n",
    "\n",
    "![](static_blog_imgs/rag_part1.png)\n",
    "\n",
    "## RAG: Step 2 - Query and Prompt LLM\n",
    "\n",
    "![](static_blog_imgs/rag_part2.png){height=60%, width=60%}\n",
    "\n",
    "## RAG  Resources\n",
    "\n",
    "- Vector DBs\n",
    "    - [weaviate](https://weaviate.io/developers/weaviate/starter-guides/generative) \n",
    "    - [pinecone](https://www.pinecone.io/learn/retrieval-augmented-generation/)\n",
    "    - [vespa](https://blog.vespa.ai/scaling-personal-ai-assistants-with-streaming-mode/)\n",
    "    - [qdrant](https://qdrant.tech/articles/what-is-rag-in-ai/)\n",
    "\n",
    "- LLM Frameworks: (not necessary for building on prod but good for learning and POC)\n",
    "    - [LlamaIndex](https://www.llamaindex.ai/)\n",
    "    - [langchain](https://python.langchain.com/docs/use_cases/question_answering/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73c9eac2c80060f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:15:59.000427Z",
     "start_time": "2024-04-30T23:15:58.996755Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fe40a3db61ed66c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# MultiModal\n",
    "\n",
    "## MultiModal {.smaller}\n",
    "\n",
    "![](https://i.pinimg.com/736x/6e/71/0d/6e710de5084379ba6a57b77e6579084f.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f2f6b7f64fbdb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## MultiModal {.smaller}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ea5a2f79cc53d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:16:08.931509Z",
     "start_time": "2024-04-30T23:15:59.003526Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The unusual aspect of this image is a man ironing clothes on an ironing board placed on top of a taxi in the middle of a busy street. This is an uncommon sight, as ironing typically takes place in domestic or commercial indoor settings. The juxtaposition of such a mundane, home-based activity with the fast-paced, outdoor environment of a city street is quite remarkable and humorous. Additionally, both the ironing board and the taxi are branded with the same logo, suggesting that this scene might be part of a promotional event or public stunt to attract attention.\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What is unusual about this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://i.pinimg.com/736x/6e/71/0d/6e710de5084379ba6a57b77e6579084f.jpg\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22fe4d3dcd17980",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## MultiModal {.smaller}\n",
    "\n",
    "![](https://media.makeameme.org/created/it-worked-fine.jpg)\n",
    "\n",
    "## MultiModal {.smaller}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "160d79cc25f6644d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T01:44:30.863286Z",
     "start_time": "2024-05-01T01:44:23.170706Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is a meme featuring two juxtaposed elements. In the background, there is a scene of a house on fire with firefighters and emergency responders at the site, attempting to manage the situation. In the foreground, there is a young girl smirking at the camera with a knowing expression. Overlaid text reads, \"IT WORKED FINE IN DEV, IT'S A DEVOPS PROBLEM NOW,\" humorously suggesting that a problem developed during the software development stage is now a problem for the DevOps team to handle. The meme uses the incongruity between the calm and mischievous expression of the girl and the chaotic scene behind her to underline its comedic message about shifting blame in a development context.\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What is in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://media.makeameme.org/created/it-worked-fine.jpg\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bc9a7843852ddb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## MultiModal\n",
    "\n",
    "![](https://storage.googleapis.com/pai-images/a6d0952a331d40489b216e7f3f1ff6ed.jpeg)\n",
    "\n",
    "## MultiModal {.smaller}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3345b909cf5890d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-30T23:16:37.171132Z",
     "start_time": "2024-04-30T23:16:26.697260Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"labels\": [\n",
      "    \"animated character\",\n",
      "    \"wizard\",\n",
      "    \"Minion\",\n",
      "    \"fantasy\",\n",
      "    \"3D illustration\",\n",
      "    \"cute\",\n",
      "    \"magic\",\n",
      "    \"staff\",\n",
      "    \"long beard\",\n",
      "    \"blue hat\",\n",
      "    \"glasses\",\n",
      "    \"overalls\",\n",
      "    \"adventure\",\n",
      "    \"comical character\",\n",
      "    \"grey beard\",\n",
      "    \"wooden staff\",\n",
      "    \"round glasses\",\n",
      "    \"yellow\",\n",
      "    \"character design\",\n",
      "    \"creative\",\n",
      "    \"digital art\",\n",
      "    \"sorcerer\",\n",
      "    \"cartoon\",\n",
      "    \"funny\",\n",
      "    \"elderly character\",\n",
      "    \"mystical\",\n",
      "    \"storybook\",\n",
      "    \"cloak\",\n",
      "    \"leather belt\",\n",
      "    \"buckle\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# | echo: true\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Give me a long list of visual search tags/keywords so I can \"\n",
    "                    \"index this image in my visual search index. Respond in JSON format {'labels': ['label1', ...]}\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": \"https://storage.googleapis.com/pai-images/a6d0952a331d40489b216e7f3f1ff6ed.jpeg\",\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"},\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c668870f90f4032",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4cb8cdb720d825e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Code Interpreter (Data Analysis)\n",
    "\n",
    "- give the LLM access to Python\n",
    "- your own little data analyst to give tasks to\n",
    "\n",
    "[example](https://chat.openai.com/c/2a470564-6868-408a-ae61-b7c1c24c40a5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a045b6845f17d265",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Fine Tuning\n",
    "\n",
    "## Fine Tuning\n",
    "- todo\n",
    "- [axolotl](https://github.com/OpenAccess-AI-Collective/axolotl?tab=readme-ov-file)\n",
    "- [torchtune](https://github.com/pytorch/torchtune)\n",
    "\n",
    "# Agents\n",
    "\n",
    "## Agents\n",
    "- todo\n",
    "\n",
    "# Resources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfb0d63b01d551e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Resources {.smaller}\n",
    "\n",
    ":::: {.columns}\n",
    "\n",
    "::: {.column width=\"33%\"}\n",
    "- [Jeremy Howard](https://x.com/jeremyphoward)\n",
    "    - [A Hackers' Guide to Language Models](https://www.youtube.com/watch?v=jkrNMKz9pWU&t=186s)\n",
    "- [Hamel Husain](https://twitter.com/HamelHusain)\n",
    "- [Maxime Labonne](https://twitter.com/maximelabonne)\n",
    "- [Sebastian Raschka](https://twitter.com/rasbt)\n",
    "- [anton](https://twitter.com/abacaj)\n",
    "- [Teknium](https://twitter.com/Teknium1)\n",
    "- [Simon Willison](https://twitter.com/simonw)\n",
    "- [ThursdAI podcast](https://open.spotify.com/show/2J3lqMPD0BUI0bF9KJYKc1?si=9eed369fd01a4ade) \n",
    "- [Latent Space](https://www.latent.space/)\n",
    "\n",
    ":::\n",
    "\n",
    "::: {.column width=\"33%\"}\n",
    "- [Jay Alammar](https://twitter.com/JayAlammar)\n",
    "- [Omar Sanseviero](https://twitter.com/osanseviero)\n",
    "- [Jason Liu](https://twitter.com/jxnlco)\n",
    "- [Omar Khattab](https://twitter.com/lateinteraction)\n",
    "- [Wing Liang](https://twitter.com/winglian)\n",
    "- [Nous Research](https://twitter.com/NousResearch)\n",
    "- [Alex Albert](https://twitter.com/alexalbert__)\n",
    "- [Matt Shumer](https://twitter.com/mattshumer_)\n",
    "- [lmsysorg](https://twitter.com/lmsysorg)\n",
    "- [Axolotl](https://twitter.com/axolotl_ai)\n",
    "- [Nathan Lambert](https://twitter.com/natolambert)\n",
    ":::\n",
    "\n",
    "::: {.column width=\"33%\"}\n",
    "- [Tanishq Abraham](https://twitter.com/iScienceLuvr)\n",
    "- [Philipp Schmid](https://twitter.com/_philschmid)\n",
    "- [Tim Dettmers](https://twitter.com/Tim_Dettmers)\n",
    "- [Eugene Yan](https://twitter.com/eugeneyan)\n",
    "- [Georgi Gerganov](https://twitter.com/ggerganov)\n",
    "- [Jim Fan](https://twitter.com/DrJimFan)\n",
    "- [swyx](https://twitter.com/swyx)\n",
    "- [Charles  Frye](https://twitter.com/charles_irl)\n",
    "- [Jonathan Frankle](https://twitter.com/jefrankle)\n",
    "- [Nils Reimers](https://twitter.com/Nils_Reimers)\n",
    "- [Alignment Lab AI](https://twitter.com/alignment_lab)\n",
    "- [people I follow](https://twitter.com/cleavey1985/following)\n",
    ":::\n",
    "\n",
    "::::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
